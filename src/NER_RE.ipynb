{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5b44bb",
   "metadata": {},
   "source": [
    "# Biomedical Named Entity Recognition and Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c4f8a",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "The primary goal of this project was to perform Named Entity Recognition (NER) and Relation Extraction (RE) in the biomedical domain. Using domain-specific pretrained models such as BioBERT and SciBERT, we aimed to:\n",
    "\n",
    "* Detect and classify biomedical entities (e.g., chemicals, diseases).\n",
    "* Extract relationships between these entities (e.g., chemical-disease associations).\n",
    "\n",
    "To achieve this, we followed a structured pipeline:\n",
    "1. Dataset preparation.\n",
    "2. Preprocessing and data transformation.\n",
    "3. Model training and evaluation.\n",
    "4. Post-processing and testing on real-world text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd93dc72",
   "metadata": {},
   "source": [
    "### Tools and Environment Setup\n",
    "\n",
    "1. **Version Control:**\n",
    "     - Repository name: `Biomedical_NER_RE`\n",
    "     - Repository structure:\n",
    "       ```\n",
    "       ├── data/                  # Contains datasets.\n",
    "       ├── src/                   # Source code for preprocessing, training, and evaluation.\n",
    "       ├── models/                # Saved model weights.\n",
    "       ├── results/               # Evaluation results and visualizations.\n",
    "       ├── README.md              # Overview and instructions\n",
    "       └── requirements.txt       # Dependencies\n",
    "       ```\n",
    "\n",
    "2. **Environment:**\n",
    "   - **Cheaha**: Ensure you've have access to the computing resources for large-scale training.\n",
    " \n",
    "     \n",
    "3. **Install necessary dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34c4758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c3fde0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bioc --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da53fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86046426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (2.32.3)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement quiet (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for quiet\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install requests -- quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdf22373",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn-crfsuite --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55dc95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TorchCRF --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2e9d4ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (4.47.0.dev0)\n",
      "Requirement already satisfied: filelock in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d8b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade accelerate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd8d5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655dfd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn_crfsuite import CRF, metrics\n",
    "import sklearn_crfsuite\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "784d4655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/pperla/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"🤖\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c8bacd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Is CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e238818",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "We utilized two biomedical datasets:\n",
    "\n",
    "- **BC5CDR**: Focused on chemical-disease associations.\n",
    "    Tasks:\n",
    "    * NER: Identify Chemical and Disease entities.\n",
    "    * Relation Extraction: Extract CID (chemical-disease interaction) relationships.\n",
    "\n",
    "\n",
    "- **CHEM_DIS_GENE**: Focused on multi-entity relationships:\n",
    "    * Entity types: Chemical, Disease, Gene.\n",
    "    * Relation types: Multi-class interactions (e.g., chem_gene:affects^expression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba46b1d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the BC5CDR dataset\n",
    "bc5cdr = load_dataset(\"bigbio/bc5cdr\", \"bc5cdr_bigbio_kb\")\n",
    "# Load the CHEM_DIS_GENE dataset\n",
    "chem_dis_gene = load_dataset(\"bigbio/chem_dis_gene\", \"chem_dis_gene_bigbio_kb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10c85cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'document_id': '227508',\n",
       " 'passages': [{'id': '1',\n",
       "   'type': 'title',\n",
       "   'text': ['Naloxone reverses the antihypertensive effect of clonidine.'],\n",
       "   'offsets': [[0, 59]]},\n",
       "  {'id': '2',\n",
       "   'type': 'abstract',\n",
       "   'text': ['In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 micrograms/kg, was inhibited or reversed by nalozone, 0.2 to 2 mg/kg. The hypotensive effect of 100 mg/kg alpha-methyldopa was also partially reversed by naloxone. Naloxone alone did not affect either blood pressure or heart rate. In brain membranes from spontaneously hypertensive rats clonidine, 10(-8) to 10(-5) M, did not influence stereoselective binding of [3H]-naloxone (8 nM), and naloxone, 10(-8) to 10(-4) M, did not influence clonidine-suppressible binding of [3H]-dihydroergocryptine (1 nM). These findings indicate that in spontaneously hypertensive rats the effects of central alpha-adrenoceptor stimulation involve activation of opiate receptors. As naloxone and clonidine do not appear to interact with the same receptor site, the observed functional antagonism suggests the release of an endogenous opiate by clonidine or alpha-methyldopa and the possible role of the opiate in the central control of sympathetic tone.'],\n",
       "   'offsets': [[60, 1135]]}],\n",
       " 'entities': [{'id': '3',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['Naloxone'],\n",
       "   'offsets': [[0, 8]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009270'}]},\n",
       "  {'id': '4',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['clonidine'],\n",
       "   'offsets': [[49, 58]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D003000'}]},\n",
       "  {'id': '5',\n",
       "   'type': 'Disease',\n",
       "   'text': ['hypertensive'],\n",
       "   'offsets': [[93, 105]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D006973'}]},\n",
       "  {'id': '6',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['clonidine'],\n",
       "   'offsets': [[181, 190]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D003000'}]},\n",
       "  {'id': '7',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['nalozone'],\n",
       "   'offsets': [[244, 252]],\n",
       "   'normalized': []},\n",
       "  {'id': '8',\n",
       "   'type': 'Disease',\n",
       "   'text': ['hypotensive'],\n",
       "   'offsets': [[274, 285]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D007022'}]},\n",
       "  {'id': '9',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['alpha-methyldopa'],\n",
       "   'offsets': [[306, 322]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D008750'}]},\n",
       "  {'id': '10',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['naloxone'],\n",
       "   'offsets': [[354, 362]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009270'}]},\n",
       "  {'id': '11',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['Naloxone'],\n",
       "   'offsets': [[364, 372]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009270'}]},\n",
       "  {'id': '12',\n",
       "   'type': 'Disease',\n",
       "   'text': ['hypertensive'],\n",
       "   'offsets': [[469, 481]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D006973'}]},\n",
       "  {'id': '13',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['clonidine'],\n",
       "   'offsets': [[487, 496]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D003000'}]},\n",
       "  {'id': '14',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['[3H]-naloxone'],\n",
       "   'offsets': [[563, 576]],\n",
       "   'normalized': []},\n",
       "  {'id': '15',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['naloxone'],\n",
       "   'offsets': [[589, 597]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009270'}]},\n",
       "  {'id': '16',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['clonidine'],\n",
       "   'offsets': [[637, 646]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D003000'}]},\n",
       "  {'id': '17',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['[3H]-dihydroergocryptine'],\n",
       "   'offsets': [[671, 695]],\n",
       "   'normalized': []},\n",
       "  {'id': '18',\n",
       "   'type': 'Disease',\n",
       "   'text': ['hypertensive'],\n",
       "   'offsets': [[750, 762]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D006973'}]},\n",
       "  {'id': '19',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['naloxone'],\n",
       "   'offsets': [[865, 873]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009270'}]},\n",
       "  {'id': '20',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['clonidine'],\n",
       "   'offsets': [[878, 887]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D003000'}]},\n",
       "  {'id': '21',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['clonidine'],\n",
       "   'offsets': [[1026, 1035]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D003000'}]},\n",
       "  {'id': '22',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['alpha-methyldopa'],\n",
       "   'offsets': [[1039, 1055]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D008750'}]}],\n",
       " 'events': [],\n",
       " 'coreferences': [],\n",
       " 'relations': [{'id': '23',\n",
       "   'type': 'CID',\n",
       "   'arg1_id': '9',\n",
       "   'arg2_id': '8',\n",
       "   'normalized': []},\n",
       "  {'id': '24',\n",
       "   'type': 'CID',\n",
       "   'arg1_id': '22',\n",
       "   'arg2_id': '8',\n",
       "   'normalized': []}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset structure\n",
    "bc5cdr_sample = bc5cdr['train'][0]\n",
    "bc5cdr_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "195760e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '10095983',\n",
       " 'document_id': '10095983',\n",
       " 'passages': [{'id': '10095983_title',\n",
       "   'type': 'title',\n",
       "   'text': ['New aspects in the management of obesity: operation and the impact of lipase inhibitors.'],\n",
       "   'offsets': [[0, 88]]},\n",
       "  {'id': '10095983_abstract',\n",
       "   'type': 'abstract',\n",
       "   'text': ['Obesity is an increasing health problem in most developed countries and its prevalence is also increasing in developing countries. There has been no great success with dietary means and life style modification for permanent weight loss. Various surgical treatment methods for obesity are now available. They are aimed at limiting oral energy intake with or without causing dumping or inducing selective maldigestion and malabsorption. Based on current literature, up to 75% of excess weight is lost by surgical treatment with concomitant disappearance of hyperlipidaemias, type 2 diabetes, hypertension or sleep apnoea. The main indication for operative treatment is morbid obesity (body mass index greater than 40 kg/m2) or severe obesity (body mass index &gt; 35 kg/m2) with comorbidities of obesity. Orlistat is a new inhibitor of pancreatic lipase enzyme. At doses of 120 mg three times per day with meals it results in a 30% reduction in dietary fat absorption, which equals approximately 200 kcal daily energy deficit. In the long term, orlistat has been shown to be more effective than placebo in reducing body weight and serum total and low-density lipoprotein cholesterol levels. Orlistat has a lowering effect on serum cholesterol independent of weight loss. Along with weight loss, orlistat also favourably affects blood pressure and glucose and insulin levels in obese individuals and in obese type 2 diabetic patients.'],\n",
       "   'offsets': [[89, 1520]]}],\n",
       " 'entities': [{'id': '10095983_e_0',\n",
       "   'type': 'Disease',\n",
       "   'text': ['obesity'],\n",
       "   'offsets': [[33, 40]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009765'}]},\n",
       "  {'id': '10095983_e_1',\n",
       "   'type': 'Disease',\n",
       "   'text': ['weight loss'],\n",
       "   'offsets': [[313, 324]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D015431'}]},\n",
       "  {'id': '10095983_e_2',\n",
       "   'type': 'Disease',\n",
       "   'text': ['obesity'],\n",
       "   'offsets': [[365, 372]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009765'}]},\n",
       "  {'id': '10095983_e_3',\n",
       "   'type': 'Disease',\n",
       "   'text': ['malabsorption'],\n",
       "   'offsets': [[509, 522]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D008286'}]},\n",
       "  {'id': '10095983_e_4',\n",
       "   'type': 'Disease',\n",
       "   'text': ['hyperlipidaemias, type 2 diabetes'],\n",
       "   'offsets': [[644, 677]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D003924'}]},\n",
       "  {'id': '10095983_e_5',\n",
       "   'type': 'Disease',\n",
       "   'text': ['hypertension'],\n",
       "   'offsets': [[679, 691]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D006973'}]},\n",
       "  {'id': '10095983_e_6',\n",
       "   'type': 'Disease',\n",
       "   'text': ['sleep apnoea'],\n",
       "   'offsets': [[695, 707]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D012891'}]},\n",
       "  {'id': '10095983_e_7',\n",
       "   'type': 'Disease',\n",
       "   'text': ['obesity'],\n",
       "   'offsets': [[763, 770]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009765'}]},\n",
       "  {'id': '10095983_e_8',\n",
       "   'type': 'Disease',\n",
       "   'text': ['obesity'],\n",
       "   'offsets': [[821, 828]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009765'}]},\n",
       "  {'id': '10095983_e_9',\n",
       "   'type': 'Disease',\n",
       "   'text': ['obesity'],\n",
       "   'offsets': [[883, 890]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009765'}]},\n",
       "  {'id': '10095983_e_10',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['Orlistat'],\n",
       "   'offsets': [[892, 900]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D000077403'}]},\n",
       "  {'id': '10095983_e_11',\n",
       "   'type': 'Disease',\n",
       "   'text': ['pancreatic lipase enzyme'],\n",
       "   'offsets': [[923, 947]],\n",
       "   'normalized': [{'db_name': 'OMIM', 'db_id': '614338'}]},\n",
       "  {'id': '10095983_e_12',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['cholesterol'],\n",
       "   'offsets': [[1318, 1329]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D002784'}]},\n",
       "  {'id': '10095983_e_13',\n",
       "   'type': 'Disease',\n",
       "   'text': ['weight loss'],\n",
       "   'offsets': [[1345, 1356]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D015431'}]},\n",
       "  {'id': '10095983_e_14',\n",
       "   'type': 'Disease',\n",
       "   'text': ['weight loss'],\n",
       "   'offsets': [[1369, 1380]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D015431'}]},\n",
       "  {'id': '10095983_e_15',\n",
       "   'type': 'Chemical',\n",
       "   'text': ['glucose'],\n",
       "   'offsets': [[1434, 1441]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D005947'}]},\n",
       "  {'id': '10095983_e_16',\n",
       "   'type': 'Gene',\n",
       "   'text': ['insulin'],\n",
       "   'offsets': [[1446, 1453]],\n",
       "   'normalized': [{'db_name': 'NCBI', 'db_id': '3630'}]},\n",
       "  {'id': '10095983_e_17',\n",
       "   'type': 'Disease',\n",
       "   'text': ['obese'],\n",
       "   'offsets': [[1464, 1469]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D009765'}]},\n",
       "  {'id': '10095983_e_18',\n",
       "   'type': 'Disease',\n",
       "   'text': ['obese type 2 diabetic'],\n",
       "   'offsets': [[1489, 1510]],\n",
       "   'normalized': [{'db_name': 'MESH', 'db_id': 'D003924'}]}],\n",
       " 'events': [],\n",
       " 'coreferences': [],\n",
       " 'relations': [{'id': '10095983_r_0',\n",
       "   'type': 'chem_gene:affects^expression',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_16',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_1',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_0',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_2',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_2',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_3',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_7',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_4',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_8',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_5',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_9',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_6',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_17',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_7',\n",
       "   'type': 'chem_disease:marker/mechanism',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_1',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_8',\n",
       "   'type': 'chem_disease:marker/mechanism',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_13',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_9',\n",
       "   'type': 'chem_disease:marker/mechanism',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_14',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_10',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_4',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_11',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_18',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_12',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_1',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_13',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_13',\n",
       "   'normalized': []},\n",
       "  {'id': '10095983_r_14',\n",
       "   'type': 'chem_disease:therapeutic',\n",
       "   'arg1_id': '10095983_e_10',\n",
       "   'arg2_id': '10095983_e_14',\n",
       "   'normalized': []}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset structure\n",
    "chem_dis_gene_sample = chem_dis_gene['train'][0]\n",
    "chem_dis_gene_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95c289",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dd7631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze the dataset\n",
    "def analyze_dataset(dataset, name):\n",
    "    num_samples = len(dataset[\"train\"])\n",
    "    entity_counts = {}\n",
    "    relation_counts = {}\n",
    "    \n",
    "    # Count entities and relations in the training data\n",
    "    for sample in dataset[\"train\"]:\n",
    "        for entity in sample.get(\"entities\", []):\n",
    "            entity_type = entity[\"type\"]\n",
    "            entity_counts[entity_type] = entity_counts.get(entity_type, 0) + 1\n",
    "        \n",
    "        for relation in sample.get(\"relations\", []):\n",
    "            relation_type = relation[\"type\"]\n",
    "            relation_counts[relation_type] = relation_counts.get(relation_type, 0) + 1\n",
    "\n",
    "    # Display the analysis results\n",
    "    print(f\"--- Analysis for {name} ---\")\n",
    "    print(f\"Number of Samples: {num_samples}\")\n",
    "    print(\"Entity Type Counts:\")\n",
    "    for entity_type, count in entity_counts.items():\n",
    "        print(f\"  {entity_type}: {count}\")\n",
    "    print(\"Relation Type Counts:\")\n",
    "    for relation_type, count in relation_counts.items():\n",
    "        print(f\"  {relation_type}: {count}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3257231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analysis for BC5CDR ---\n",
      "Number of Samples: 500\n",
      "Entity Type Counts:\n",
      "  Chemical: 5207\n",
      "  Disease: 4363\n",
      "Relation Type Counts:\n",
      "  CID: 15072\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_dataset(bc5cdr, \"BC5CDR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a483e2",
   "metadata": {},
   "source": [
    "#### **BC5CDR**\n",
    "- **Number of Samples**: 500\n",
    "- **Entities**:\n",
    "  - **Chemical**: 5207 occurrences.\n",
    "  - **Disease**: 4363 occurrences.\n",
    "- **Relations**:\n",
    "  - **CID (Chemical-Induced Disease)**: 15072 instances.\n",
    "\n",
    "**Implications**:\n",
    "- This dataset is well-suited for **Chemical-Disease Named Entity Recognition (NER)** and **Chemical-Disease Relation Extraction (RE)** tasks.\n",
    "- CID relations can serve as a focused objective for binary or multi-class relation extraction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3475b4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analysis for CHEM_DIS_GENE ---\n",
      "Number of Samples: 523\n",
      "Entity Type Counts:\n",
      "  Disease: 2931\n",
      "  Chemical: 5739\n",
      "  Gene: 5578\n",
      "Relation Type Counts:\n",
      "  chem_gene:affects^expression: 898\n",
      "  chem_disease:therapeutic: 5214\n",
      "  chem_disease:marker/mechanism: 8047\n",
      "  chem_gene:affects^binding: 3345\n",
      "  chem_gene:increases^activity: 5272\n",
      "  gene_disease:marker/mechanism: 7744\n",
      "  chem_gene:decreases^activity: 5467\n",
      "  chem_gene:increases^metabolic_processing: 2289\n",
      "  chem_gene:decreases^expression: 6806\n",
      "  chem_gene:increases^expression: 7972\n",
      "  chem_gene:decreases^transport: 284\n",
      "  chem_gene:affects^activity: 515\n",
      "  chem_gene:decreases^metabolic_processing: 1196\n",
      "  gene_disease:therapeutic: 2204\n",
      "  chem_gene:affects^metabolic_processing: 231\n",
      "  chem_gene:affects^localization: 889\n",
      "  chem_gene:increases^transport: 778\n",
      "  chem_gene:affects^transport: 263\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_dataset(chem_dis_gene, \"CHEM_DIS_GENE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dc04d",
   "metadata": {},
   "source": [
    "#### **CHEM_DIS_GENE**\n",
    "- **Number of Samples**: 523\n",
    "- **Entities**:\n",
    "  - **Disease**: 2931 occurrences.\n",
    "  - **Chemical**: 5739 occurrences.\n",
    "  - **Gene**: 5578 occurrences.\n",
    "- **Relations**: 18 relation types, including:\n",
    "  - High-frequency types:\n",
    "    - `chem_disease:therapeutic`: 5214 occurrences.\n",
    "    - `chem_gene:increases^expression`: 7972 occurrences.\n",
    "    - `chem_gene:decreases^expression`: 6806 occurrences.\n",
    "  - Low-frequency types:\n",
    "    - `chem_gene:decreases^transport`: 284 occurrences.\n",
    "    - `chem_gene:affects^metabolic_processing`: 231 occurrences.\n",
    "\n",
    "### **Implications**:\n",
    "- This dataset is ideal for **multi-entity NER** (Chemical, Disease, Gene) and **multi-class RE** involving complex relationships.\n",
    "- The diversity in relation types provides an opportunity to build and test **multi-class classifiers** or graph-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fc942be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bc5cdr_entity_counts = {\"Chemical\": 1200, \"Disease\": 1000}\n",
    "bc5cdr_relation_counts = {\"Chemical-Disease\": 500}\n",
    "\n",
    "chem_dis_gene_entity_counts = {\"Chemical\": 1500, \"Disease\": 1300, \"Gene\": 800}\n",
    "chem_dis_gene_relation_counts = {\"Chemical-Disease\": 400, \"Chemical-Gene\": 350, \"Gene-Disease\": 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee9ef55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts(counts, title, xlabel):\n",
    "    labels, values = zip(*counts.items())\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.bar(labels, values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccd44345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_counts(bc5cdr_entity_counts, \"BC5CDR Entity Type Distribution\", \"Entity Types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "907eef35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_counts(bc5cdr_relation_counts, \"BC5CDR Relation Type Distribution\", \"Relation Types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38f6dc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_counts(chem_dis_gene_entity_counts, \"CHEM_DIS_GENE Entity Type Distribution\", \"Entity Types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73a1ec6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_counts(chem_dis_gene_relation_counts, \"CHEM_DIS_GENE Relation Type Distribution\", \"Relation Types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4c656",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "**Entity Normalization**\n",
    "\n",
    "Used APIs like MeSH(Medical Subject Headings) to normalize Chemical and Disease entities into standardized formats for consistency.\n",
    "\n",
    "**How MeSH is Integrated in the Project**\n",
    "\n",
    "In the context of your NER and RE project, MeSH plays a key role in entity normalization. When the system detects a biomedical entity (e.g., a disease or chemical), it normalizes that entity to its corresponding MeSH ID to ensure consistency and clarity. This enables the model to:\n",
    "\n",
    "* **MeSH Terminology Examples**\n",
    "    - MeSH Term for Drug:\n",
    "        - `\"Aspirin\" -> D001249`\n",
    "        - `\"Paracetamol\" -> D010153`\n",
    "    - MeSH Term for Disease:\n",
    "        - `\"Cancer\" -> D002283`\n",
    "        - `\"Diabetes\" -> D003924`\n",
    "    - MeSH Term for Biological Process:\n",
    "        - `\"Gene Expression\" -> D005913`\n",
    "\n",
    "Map entities in the dataset (like Chemical or Disease) to standard biomedical terms.\n",
    "\n",
    "Disambiguate similar terms (e.g., \"Aspirin\" and \"acetylsalicylic acid\").\n",
    "\n",
    "Improve the accuracy of relation extraction, especially when extracting relationships between chemicals, diseases, and genes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39236b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_entity_with_mesh(entity_name):\n",
    "    \"\"\"\n",
    "    Normalize entity names using the MeSH API.\n",
    "    Args:\n",
    "        entity_name (str): The name of the entity (Chemical/Disease).\n",
    "    Returns:\n",
    "        dict: Normalized MeSH ID and term.\n",
    "    \"\"\"\n",
    "    base_url = \"https://id.nlm.nih.gov/mesh/lookup/term\"\n",
    "    params = {\"label\": entity_name, \"match\": \"exact\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if data:\n",
    "            return {\"id\": data[0][\"resource\"], \"label\": data[0][\"label\"]}\n",
    "        else:\n",
    "            return {\"id\": None, \"label\": None}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error querying MeSH API for {entity_name}: {e}\")\n",
    "        return {\"id\": None, \"label\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af7639d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aspirin': {'id': 'http://id.nlm.nih.gov/mesh/T003713', 'label': 'Aspirin'},\n",
       " 'Fever': {'id': 'http://id.nlm.nih.gov/mesh/T016284', 'label': 'Fever'},\n",
       " 'Ibuprofen': {'id': 'http://id.nlm.nih.gov/mesh/T021099',\n",
       "  'label': 'Ibuprofen'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "example_entities = [\"Aspirin\", \"Fever\", \"Ibuprofen\"]\n",
    "normalized_entities = {entity: normalize_entity_with_mesh(entity) for entity in example_entities}\n",
    "normalized_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5a80fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspirin {'id': 'http://id.nlm.nih.gov/mesh/T003713', 'label': 'Aspirin'}\n",
      "Fever {'id': 'http://id.nlm.nih.gov/mesh/T016284', 'label': 'Fever'}\n",
      "Ibuprofen {'id': 'http://id.nlm.nih.gov/mesh/T021099', 'label': 'Ibuprofen'}\n"
     ]
    }
   ],
   "source": [
    "def normalize_entity_with_mesh(entity_name):\n",
    "    base_url = \"https://id.nlm.nih.gov/mesh/lookup/term\"\n",
    "    params = {\"label\": entity_name, \"match\": \"exact\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if data:\n",
    "            return {\"id\": data[0][\"resource\"], \"label\": data[0][\"label\"]}\n",
    "        else:\n",
    "            return {\"id\": None, \"label\": None}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error querying MeSH API for {entity_name}: {e}\")\n",
    "        return {\"id\": None, \"label\": None}\n",
    "\n",
    "# Test with example entities\n",
    "example_entities = [\"Aspirin\", \"Fever\", \"Ibuprofen\"]\n",
    "for entity in example_entities:\n",
    "    print(entity, normalize_entity_with_mesh(entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e704f9",
   "metadata": {},
   "source": [
    "## Data Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52114dea",
   "metadata": {},
   "source": [
    "### **NER - BIO Tagging Format**\n",
    "\n",
    "Transformed raw datasets into model-ready formats. The BIO tagging scheme represents:\n",
    "\n",
    "* `B-<entity_type>:` Beginning of an entity.\n",
    "* `I-<entity_type>:` Inside the entity.\n",
    "* `O:` Outside any entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca870308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_bio_tag(text, entities):\n",
    "    \"\"\"\n",
    "    Convert text and entities into token-level BIO tagging format.\n",
    "    Args:\n",
    "        text (str): The raw text.\n",
    "        entities (list of dict): List of entities with start, end, and type.\n",
    "    Returns:\n",
    "        list of tuples: Token-BIO tag pairs.\n",
    "    \"\"\"\n",
    "    import nltk\n",
    "    nltk.download(\"punkt\", quiet=True)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    bio_tags = [\"O\"] * len(tokens)\n",
    "\n",
    "    for entity in entities:\n",
    "        entity_text = entity[\"text\"]\n",
    "        entity_start = entity[\"offsets\"][0][0]\n",
    "        entity_end = entity[\"offsets\"][0][1]\n",
    "        entity_type = entity[\"type\"]\n",
    "\n",
    "        # Locate entity in tokenized text\n",
    "        token_index = 0\n",
    "        for i, token in enumerate(tokens):\n",
    "            token_start = text.find(token, token_index)\n",
    "            token_end = token_start + len(token)\n",
    "            token_index = token_end\n",
    "\n",
    "            if token_start >= entity_start and token_end <= entity_end:\n",
    "                if token_start == entity_start:\n",
    "                    bio_tags[i] = f\"B-{entity_type}\"\n",
    "                else:\n",
    "                    bio_tags[i] = f\"I-{entity_type}\"\n",
    "\n",
    "    return list(zip(tokens, bio_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00411402",
   "metadata": {},
   "source": [
    "### **Relation Extraction - Tuple Format**\n",
    "\n",
    "The relation extraction format organizes:\n",
    "\n",
    "`<entity1, relation, entity2>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "807828fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relation_tuples(relations, entities):\n",
    "    \"\"\"\n",
    "    Extract relations in tuple format <entity1, relation, entity2>.\n",
    "    Args:\n",
    "        relations (list of dict): List of relations with entity IDs.\n",
    "        entities (list of dict): List of entities with IDs and types.\n",
    "    Returns:\n",
    "        list of tuples: Relations in <entity1, relation, entity2> format.\n",
    "    \"\"\"\n",
    "    entity_map = {entity[\"id\"]: entity for entity in entities}\n",
    "    relation_tuples = []\n",
    "\n",
    "    for relation in relations:\n",
    "        head_entity = entity_map.get(relation[\"arg1_id\"])\n",
    "        tail_entity = entity_map.get(relation[\"arg2_id\"])\n",
    "        if head_entity and tail_entity:\n",
    "            relation_tuples.append((head_entity[\"text\"], relation[\"type\"], tail_entity[\"text\"]))\n",
    "\n",
    "    return relation_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4eac500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_passages(passages):\n",
    "    \"\"\"\n",
    "    Concatenate text from passages into a single string.\n",
    "    Args:\n",
    "        passages (list): List of passage dictionaries with 'text' field.\n",
    "    Returns:\n",
    "        str: Concatenated text.\n",
    "    \"\"\"\n",
    "    return \" \".join([\" \".join(passage[\"text\"]) for passage in passages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f6939b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/pperla/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/pperla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Ensure necessary NLTK resources are downloaded\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f498c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 s, sys: 3.24 s, total: 34.8 s\n",
      "Wall time: 16min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process BC5CDR dataset\n",
    "bc5cdr_processed = []\n",
    "for sample in bc5cdr[\"train\"]:\n",
    "    # Extract and concatenate text\n",
    "    sample_text = concatenate_passages(sample[\"passages\"])\n",
    "    \n",
    "    # Tokenize and BIO tag\n",
    "    bio_tags = tokenize_and_bio_tag(sample_text, sample[\"entities\"])\n",
    "    \n",
    "    # Extract relation tuples\n",
    "    relation_tuples = extract_relation_tuples(sample[\"relations\"], sample[\"entities\"])\n",
    "    \n",
    "    # Normalize entities\n",
    "    normalized_entities = [normalize_entity_with_mesh(entity[\"text\"][0]) for entity in sample[\"entities\"]]\n",
    "    \n",
    "    # Append processed sample\n",
    "    bc5cdr_processed.append({\n",
    "        \"bio_tags\": bio_tags,\n",
    "        \"relation_tuples\": relation_tuples,\n",
    "        \"normalized_entities\": normalized_entities\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40a26dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.4 s, sys: 4.63 s, total: 52 s\n",
      "Wall time: 23min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process CHEM_DIS_GENE dataset\n",
    "chem_dis_gene_processed = []\n",
    "for sample in chem_dis_gene[\"train\"]:\n",
    "    # Extract and concatenate text\n",
    "    sample_text = concatenate_passages(sample[\"passages\"])\n",
    "    \n",
    "    # Tokenize and BIO tag\n",
    "    bio_tags = tokenize_and_bio_tag(sample_text, sample[\"entities\"])\n",
    "    \n",
    "    # Extract relation tuples\n",
    "    relation_tuples = extract_relation_tuples(sample[\"relations\"], sample[\"entities\"])\n",
    "    \n",
    "    # Normalize entities\n",
    "    normalized_entities = [normalize_entity_with_mesh(entity[\"text\"][0]) for entity in sample[\"entities\"]]\n",
    "    \n",
    "    # Append processed sample\n",
    "    chem_dis_gene_processed.append({\n",
    "        \"bio_tags\": bio_tags,\n",
    "        \"relation_tuples\": relation_tuples,\n",
    "        \"normalized_entities\": normalized_entities\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f18baf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC5CDR Processed Sample: {'bio_tags': [('Naloxone', 'B-Chemical'), ('reverses', 'O'), ('the', 'O'), ('antihypertensive', 'O'), ('effect', 'O'), ('of', 'O'), ('clonidine', 'B-Chemical'), ('.', 'O'), ('In', 'O'), ('unanesthetized', 'O'), (',', 'O'), ('spontaneously', 'O'), ('hypertensive', 'B-Disease'), ('rats', 'O'), ('the', 'O'), ('decrease', 'O'), ('in', 'O'), ('blood', 'O'), ('pressure', 'O'), ('and', 'O'), ('heart', 'O'), ('rate', 'O'), ('produced', 'O'), ('by', 'O'), ('intravenous', 'O'), ('clonidine', 'B-Chemical'), (',', 'O'), ('5', 'O'), ('to', 'O'), ('20', 'O'), ('micrograms/kg', 'O'), (',', 'O'), ('was', 'O'), ('inhibited', 'O'), ('or', 'O'), ('reversed', 'O'), ('by', 'O'), ('nalozone', 'B-Chemical'), (',', 'O'), ('0.2', 'O'), ('to', 'O'), ('2', 'O'), ('mg/kg', 'O'), ('.', 'O'), ('The', 'O'), ('hypotensive', 'B-Disease'), ('effect', 'O'), ('of', 'O'), ('100', 'O'), ('mg/kg', 'O'), ('alpha-methyldopa', 'B-Chemical'), ('was', 'O'), ('also', 'O'), ('partially', 'O'), ('reversed', 'O'), ('by', 'O'), ('naloxone', 'B-Chemical'), ('.', 'O'), ('Naloxone', 'B-Chemical'), ('alone', 'O'), ('did', 'O'), ('not', 'O'), ('affect', 'O'), ('either', 'O'), ('blood', 'O'), ('pressure', 'O'), ('or', 'O'), ('heart', 'O'), ('rate', 'O'), ('.', 'O'), ('In', 'O'), ('brain', 'O'), ('membranes', 'O'), ('from', 'O'), ('spontaneously', 'O'), ('hypertensive', 'B-Disease'), ('rats', 'O'), ('clonidine', 'B-Chemical'), (',', 'O'), ('10', 'O'), ('(', 'O'), ('-8', 'O'), (')', 'O'), ('to', 'O'), ('10', 'O'), ('(', 'O'), ('-5', 'O'), (')', 'O'), ('M', 'O'), (',', 'O'), ('did', 'O'), ('not', 'O'), ('influence', 'O'), ('stereoselective', 'O'), ('binding', 'O'), ('of', 'O'), ('[', 'B-Chemical'), ('3H', 'I-Chemical'), (']', 'I-Chemical'), ('-naloxone', 'I-Chemical'), ('(', 'O'), ('8', 'O'), ('nM', 'O'), (')', 'O'), (',', 'O'), ('and', 'O'), ('naloxone', 'B-Chemical'), (',', 'O'), ('10', 'O'), ('(', 'O'), ('-8', 'O'), (')', 'O'), ('to', 'O'), ('10', 'O'), ('(', 'O'), ('-4', 'O'), (')', 'O'), ('M', 'O'), (',', 'O'), ('did', 'O'), ('not', 'O'), ('influence', 'O'), ('clonidine-suppressible', 'O'), ('binding', 'O'), ('of', 'O'), ('[', 'B-Chemical'), ('3H', 'I-Chemical'), (']', 'I-Chemical'), ('-dihydroergocryptine', 'I-Chemical'), ('(', 'O'), ('1', 'O'), ('nM', 'O'), (')', 'O'), ('.', 'O'), ('These', 'O'), ('findings', 'O'), ('indicate', 'O'), ('that', 'O'), ('in', 'O'), ('spontaneously', 'O'), ('hypertensive', 'B-Disease'), ('rats', 'O'), ('the', 'O'), ('effects', 'O'), ('of', 'O'), ('central', 'O'), ('alpha-adrenoceptor', 'O'), ('stimulation', 'O'), ('involve', 'O'), ('activation', 'O'), ('of', 'O'), ('opiate', 'O'), ('receptors', 'O'), ('.', 'O'), ('As', 'O'), ('naloxone', 'B-Chemical'), ('and', 'O'), ('clonidine', 'B-Chemical'), ('do', 'O'), ('not', 'O'), ('appear', 'O'), ('to', 'O'), ('interact', 'O'), ('with', 'O'), ('the', 'O'), ('same', 'O'), ('receptor', 'O'), ('site', 'O'), (',', 'O'), ('the', 'O'), ('observed', 'O'), ('functional', 'O'), ('antagonism', 'O'), ('suggests', 'O'), ('the', 'O'), ('release', 'O'), ('of', 'O'), ('an', 'O'), ('endogenous', 'O'), ('opiate', 'O'), ('by', 'O'), ('clonidine', 'B-Chemical'), ('or', 'O'), ('alpha-methyldopa', 'B-Chemical'), ('and', 'O'), ('the', 'O'), ('possible', 'O'), ('role', 'O'), ('of', 'O'), ('the', 'O'), ('opiate', 'O'), ('in', 'O'), ('the', 'O'), ('central', 'O'), ('control', 'O'), ('of', 'O'), ('sympathetic', 'O'), ('tone', 'O'), ('.', 'O')], 'relation_tuples': [(['alpha-methyldopa'], 'CID', ['hypotensive']), (['alpha-methyldopa'], 'CID', ['hypotensive'])], 'normalized_entities': [{'id': 'http://id.nlm.nih.gov/mesh/T027668', 'label': 'Naloxone'}, {'id': 'http://id.nlm.nih.gov/mesh/T008702', 'label': 'Clonidine'}, {'id': None, 'label': None}, {'id': 'http://id.nlm.nih.gov/mesh/T008702', 'label': 'Clonidine'}, {'id': None, 'label': None}, {'id': None, 'label': None}, {'id': 'http://id.nlm.nih.gov/mesh/T026072', 'label': 'alpha-Methyldopa'}, {'id': 'http://id.nlm.nih.gov/mesh/T027668', 'label': 'Naloxone'}, {'id': 'http://id.nlm.nih.gov/mesh/T027668', 'label': 'Naloxone'}, {'id': None, 'label': None}, {'id': 'http://id.nlm.nih.gov/mesh/T008702', 'label': 'Clonidine'}, {'id': None, 'label': None}, {'id': 'http://id.nlm.nih.gov/mesh/T027668', 'label': 'Naloxone'}, {'id': 'http://id.nlm.nih.gov/mesh/T008702', 'label': 'Clonidine'}, {'id': None, 'label': None}, {'id': None, 'label': None}, {'id': 'http://id.nlm.nih.gov/mesh/T027668', 'label': 'Naloxone'}, {'id': 'http://id.nlm.nih.gov/mesh/T008702', 'label': 'Clonidine'}, {'id': 'http://id.nlm.nih.gov/mesh/T008702', 'label': 'Clonidine'}, {'id': 'http://id.nlm.nih.gov/mesh/T026072', 'label': 'alpha-Methyldopa'}]}\n"
     ]
    }
   ],
   "source": [
    "# Example outputs\n",
    "print(\"BC5CDR Processed Sample:\", bc5cdr_processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f69a4a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEM_DIS_GENE Processed Sample: {'bio_tags': [('New', 'O'), ('aspects', 'O'), ('in', 'O'), ('the', 'O'), ('management', 'O'), ('of', 'O'), ('obesity', 'B-Disease'), (':', 'O'), ('operation', 'O'), ('and', 'O'), ('the', 'O'), ('impact', 'O'), ('of', 'O'), ('lipase', 'O'), ('inhibitors', 'O'), ('.', 'O'), ('Obesity', 'O'), ('is', 'O'), ('an', 'O'), ('increasing', 'O'), ('health', 'O'), ('problem', 'O'), ('in', 'O'), ('most', 'O'), ('developed', 'O'), ('countries', 'O'), ('and', 'O'), ('its', 'O'), ('prevalence', 'O'), ('is', 'O'), ('also', 'O'), ('increasing', 'O'), ('in', 'O'), ('developing', 'O'), ('countries', 'O'), ('.', 'O'), ('There', 'O'), ('has', 'O'), ('been', 'O'), ('no', 'O'), ('great', 'O'), ('success', 'O'), ('with', 'O'), ('dietary', 'O'), ('means', 'O'), ('and', 'O'), ('life', 'O'), ('style', 'O'), ('modification', 'O'), ('for', 'O'), ('permanent', 'O'), ('weight', 'B-Disease'), ('loss', 'I-Disease'), ('.', 'O'), ('Various', 'O'), ('surgical', 'O'), ('treatment', 'O'), ('methods', 'O'), ('for', 'O'), ('obesity', 'B-Disease'), ('are', 'O'), ('now', 'O'), ('available', 'O'), ('.', 'O'), ('They', 'O'), ('are', 'O'), ('aimed', 'O'), ('at', 'O'), ('limiting', 'O'), ('oral', 'O'), ('energy', 'O'), ('intake', 'O'), ('with', 'O'), ('or', 'O'), ('without', 'O'), ('causing', 'O'), ('dumping', 'O'), ('or', 'O'), ('inducing', 'O'), ('selective', 'O'), ('maldigestion', 'O'), ('and', 'O'), ('malabsorption', 'B-Disease'), ('.', 'O'), ('Based', 'O'), ('on', 'O'), ('current', 'O'), ('literature', 'O'), (',', 'O'), ('up', 'O'), ('to', 'O'), ('75', 'O'), ('%', 'O'), ('of', 'O'), ('excess', 'O'), ('weight', 'O'), ('is', 'O'), ('lost', 'O'), ('by', 'O'), ('surgical', 'O'), ('treatment', 'O'), ('with', 'O'), ('concomitant', 'O'), ('disappearance', 'O'), ('of', 'O'), ('hyperlipidaemias', 'B-Disease'), (',', 'I-Disease'), ('type', 'I-Disease'), ('2', 'I-Disease'), ('diabetes', 'I-Disease'), (',', 'O'), ('hypertension', 'B-Disease'), ('or', 'O'), ('sleep', 'B-Disease'), ('apnoea', 'I-Disease'), ('.', 'O'), ('The', 'O'), ('main', 'O'), ('indication', 'O'), ('for', 'O'), ('operative', 'O'), ('treatment', 'O'), ('is', 'O'), ('morbid', 'O'), ('obesity', 'B-Disease'), ('(', 'O'), ('body', 'O'), ('mass', 'O'), ('index', 'O'), ('greater', 'O'), ('than', 'O'), ('40', 'O'), ('kg/m2', 'O'), (')', 'O'), ('or', 'O'), ('severe', 'O'), ('obesity', 'B-Disease'), ('(', 'O'), ('body', 'O'), ('mass', 'O'), ('index', 'O'), ('&', 'O'), ('gt', 'O'), (';', 'O'), ('35', 'O'), ('kg/m2', 'O'), (')', 'O'), ('with', 'O'), ('comorbidities', 'O'), ('of', 'O'), ('obesity', 'B-Disease'), ('.', 'O'), ('Orlistat', 'B-Chemical'), ('is', 'O'), ('a', 'O'), ('new', 'O'), ('inhibitor', 'O'), ('of', 'O'), ('pancreatic', 'B-Disease'), ('lipase', 'I-Disease'), ('enzyme', 'I-Disease'), ('.', 'O'), ('At', 'O'), ('doses', 'O'), ('of', 'O'), ('120', 'O'), ('mg', 'O'), ('three', 'O'), ('times', 'O'), ('per', 'O'), ('day', 'O'), ('with', 'O'), ('meals', 'O'), ('it', 'O'), ('results', 'O'), ('in', 'O'), ('a', 'O'), ('30', 'O'), ('%', 'O'), ('reduction', 'O'), ('in', 'O'), ('dietary', 'O'), ('fat', 'O'), ('absorption', 'O'), (',', 'O'), ('which', 'O'), ('equals', 'O'), ('approximately', 'O'), ('200', 'O'), ('kcal', 'O'), ('daily', 'O'), ('energy', 'O'), ('deficit', 'O'), ('.', 'O'), ('In', 'O'), ('the', 'O'), ('long', 'O'), ('term', 'O'), (',', 'O'), ('orlistat', 'O'), ('has', 'O'), ('been', 'O'), ('shown', 'O'), ('to', 'O'), ('be', 'O'), ('more', 'O'), ('effective', 'O'), ('than', 'O'), ('placebo', 'O'), ('in', 'O'), ('reducing', 'O'), ('body', 'O'), ('weight', 'O'), ('and', 'O'), ('serum', 'O'), ('total', 'O'), ('and', 'O'), ('low-density', 'O'), ('lipoprotein', 'O'), ('cholesterol', 'O'), ('levels', 'O'), ('.', 'O'), ('Orlistat', 'O'), ('has', 'O'), ('a', 'O'), ('lowering', 'O'), ('effect', 'O'), ('on', 'O'), ('serum', 'O'), ('cholesterol', 'B-Chemical'), ('independent', 'O'), ('of', 'O'), ('weight', 'B-Disease'), ('loss', 'I-Disease'), ('.', 'O'), ('Along', 'O'), ('with', 'O'), ('weight', 'B-Disease'), ('loss', 'I-Disease'), (',', 'O'), ('orlistat', 'O'), ('also', 'O'), ('favourably', 'O'), ('affects', 'O'), ('blood', 'O'), ('pressure', 'O'), ('and', 'O'), ('glucose', 'B-Chemical'), ('and', 'O'), ('insulin', 'B-Gene'), ('levels', 'O'), ('in', 'O'), ('obese', 'B-Disease'), ('individuals', 'O'), ('and', 'O'), ('in', 'O'), ('obese', 'B-Disease'), ('type', 'I-Disease'), ('2', 'I-Disease'), ('diabetic', 'I-Disease'), ('patients', 'O'), ('.', 'O')], 'relation_tuples': [(['Orlistat'], 'chem_gene:affects^expression', ['insulin']), (['Orlistat'], 'chem_disease:therapeutic', ['obesity']), (['Orlistat'], 'chem_disease:therapeutic', ['obesity']), (['Orlistat'], 'chem_disease:therapeutic', ['obesity']), (['Orlistat'], 'chem_disease:therapeutic', ['obesity']), (['Orlistat'], 'chem_disease:therapeutic', ['obesity']), (['Orlistat'], 'chem_disease:therapeutic', ['obese']), (['Orlistat'], 'chem_disease:marker/mechanism', ['weight loss']), (['Orlistat'], 'chem_disease:marker/mechanism', ['weight loss']), (['Orlistat'], 'chem_disease:marker/mechanism', ['weight loss']), (['Orlistat'], 'chem_disease:therapeutic', ['hyperlipidaemias, type 2 diabetes']), (['Orlistat'], 'chem_disease:therapeutic', ['obese type 2 diabetic']), (['Orlistat'], 'chem_disease:therapeutic', ['weight loss']), (['Orlistat'], 'chem_disease:therapeutic', ['weight loss']), (['Orlistat'], 'chem_disease:therapeutic', ['weight loss'])], 'normalized_entities': [{'id': 'http://id.nlm.nih.gov/mesh/T029022', 'label': 'Obesity'}, {'id': 'http://id.nlm.nih.gov/mesh/T045556', 'label': 'Weight Loss'}, {'id': 'http://id.nlm.nih.gov/mesh/T029022', 'label': 'Obesity'}, {'id': None, 'label': None}, {'id': None, 'label': None}, {'id': 'http://id.nlm.nih.gov/mesh/T020937', 'label': 'Hypertension'}, {'id': None, 'label': None}, {'id': 'http://id.nlm.nih.gov/mesh/T029022', 'label': 'Obesity'}, {'id': 'http://id.nlm.nih.gov/mesh/T029022', 'label': 'Obesity'}, {'id': 'http://id.nlm.nih.gov/mesh/T029022', 'label': 'Obesity'}, {'id': 'http://id.nlm.nih.gov/mesh/T000939569', 'label': 'Orlistat'}, {'id': None, 'label': None}, {'id': 'http://id.nlm.nih.gov/mesh/T008078', 'label': 'Cholesterol'}, {'id': 'http://id.nlm.nih.gov/mesh/T045556', 'label': 'Weight Loss'}, {'id': 'http://id.nlm.nih.gov/mesh/T045556', 'label': 'Weight Loss'}, {'id': 'http://id.nlm.nih.gov/mesh/T018006', 'label': 'Glucose'}, {'id': 'http://id.nlm.nih.gov/mesh/T021939', 'label': 'Insulin'}, {'id': None, 'label': None}, {'id': None, 'label': None}]}\n"
     ]
    }
   ],
   "source": [
    "print(\"CHEM_DIS_GENE Processed Sample:\", chem_dis_gene_processed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707709c1",
   "metadata": {},
   "source": [
    "### **Splitting the data**\n",
    "\n",
    "Created training/validation/test splits (70/15/15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3ee501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(processed_data, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    Split the dataset into train, validation, and test sets.\n",
    "    Args:\n",
    "        processed_data (list): List of processed data samples.\n",
    "        train_ratio (float): Proportion of the data for training.\n",
    "        val_ratio (float): Proportion of the data for validation.\n",
    "        test_ratio (float): Proportion of the data for testing.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "    Returns:\n",
    "        dict: Split datasets with 'train', 'val', and 'test' keys.\n",
    "    \"\"\"\n",
    "    # Shuffle the data\n",
    "    random.seed(seed)\n",
    "    random.shuffle(processed_data)\n",
    "    \n",
    "    # Compute split indices\n",
    "    total = len(processed_data)\n",
    "    train_end = int(total * train_ratio)\n",
    "    val_end = train_end + int(total * val_ratio)\n",
    "    \n",
    "    # Split data\n",
    "    train_data = processed_data[:train_end]\n",
    "    val_data = processed_data[train_end:val_end]\n",
    "    test_data = processed_data[val_end:]\n",
    "    \n",
    "    return {\"train\": train_data, \"val\": val_data, \"test\": test_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa17f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the processed BC5CDR dataset\n",
    "bc5cdr_splits = split_dataset(bc5cdr_processed)\n",
    "\n",
    "# Split the processed CHEM_DIS_GENE dataset\n",
    "chem_dis_gene_splits = split_dataset(chem_dis_gene_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b97401d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC5CDR Train Sample: 350\n",
      "BC5CDR Validation Sample: 75\n",
      "BC5CDR Test Sample: 75\n"
     ]
    }
   ],
   "source": [
    "print(\"BC5CDR Train Sample:\", len(bc5cdr_splits[\"train\"]))\n",
    "print(\"BC5CDR Validation Sample:\", len(bc5cdr_splits[\"val\"]))\n",
    "print(\"BC5CDR Test Sample:\", len(bc5cdr_splits[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "018dd7da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEM_DIS_GENE Train Sample: 366\n",
      "CHEM_DIS_GENE Validation Sample: 78\n",
      "CHEM_DIS_GENE Test Sample: 79\n"
     ]
    }
   ],
   "source": [
    "print(\"CHEM_DIS_GENE Train Sample:\", len(chem_dis_gene_splits[\"train\"]))\n",
    "print(\"CHEM_DIS_GENE Validation Sample:\", len(chem_dis_gene_splits[\"val\"]))\n",
    "print(\"CHEM_DIS_GENE Test Sample:\", len(chem_dis_gene_splits[\"test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38dad93",
   "metadata": {},
   "source": [
    "## Model Selection and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59510f",
   "metadata": {},
   "source": [
    "## Baseline Models\n",
    "\n",
    "### Named Entity Recognition (NER)\n",
    "- Approach: We will train a CRF (It is a type of probabilistic model that uses conditional probabilities to predict outcomes.)\n",
    "- Features: Each token represented by its raw text (simple, no embeddings).\n",
    "- Algorithm: CRF with lbfgs optimization.\n",
    "- Evaluation: Predicted BIO tags were compared to ground truth tags using precision, recall, and F1-score.\n",
    "\n",
    "### Relation Extraction (RE)\n",
    "- Approach: We will train a Logistic Regression model\n",
    "- Features: Textual contexts generated by combining entity pairs and their relationship type.\n",
    "- Vectorization: Used CountVectorizer to convert textual contexts into numeric feature vectors.\n",
    "- Evaluation: Predicted relationships were compared to ground truth using precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dd6d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ner_data(dataset):\n",
    "    \"\"\"\n",
    "    Prepares data for CRF-based NER model.\n",
    "    Args:\n",
    "        dataset (list): Dataset with BIO-tagged tokens.\n",
    "    Returns:\n",
    "        list, list: Features and labels for the CRF model.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    for sample in dataset:\n",
    "        tokens, tags = zip(*sample[\"bio_tags\"])\n",
    "        features.append([{\"word\": token} for token in tokens])  # Feature: word\n",
    "        labels.append(tags)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f6f6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_samples(dataset, negative_ratio=1.0):\n",
    "    \"\"\"\n",
    "    Generate negative samples for the BC5CDR dataset.\n",
    "    Args:\n",
    "        dataset (list): Processed dataset with relation tuples.\n",
    "        negative_ratio (float): Ratio of negative samples to positive samples.\n",
    "    Returns:\n",
    "        list: Dataset with added negative samples.\n",
    "    \"\"\"\n",
    "    updated_dataset = []\n",
    "    for sample in dataset:\n",
    "        positive_relations = sample[\"relation_tuples\"]\n",
    "        entities = [entity[\"label\"] for entity in sample[\"normalized_entities\"]]\n",
    "        negative_relations = []\n",
    "\n",
    "        # Generate all possible entity pairs\n",
    "        entity_pairs = [(e1, e2) for e1 in entities for e2 in entities if e1 != e2]\n",
    "        \n",
    "        # Create negative samples (pairs without CID relation)\n",
    "        for entity1, entity2 in entity_pairs:\n",
    "            if not any(entity1 == r[0] and entity2 == r[2] for r in positive_relations):\n",
    "                negative_relations.append((entity1, \"NO_RELATION\", entity2))\n",
    "        \n",
    "        # Limit negative samples\n",
    "        num_negative = int(len(positive_relations) * negative_ratio)\n",
    "        negative_relations = negative_relations[:num_negative]\n",
    "        \n",
    "        # Combine positive and negative samples\n",
    "        updated_sample = {\n",
    "            \"relation_tuples\": positive_relations + negative_relations,\n",
    "            \"bio_tags\": sample[\"bio_tags\"],\n",
    "            \"normalized_entities\": sample[\"normalized_entities\"],\n",
    "        }\n",
    "        updated_dataset.append(updated_sample)\n",
    "    return updated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5189244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_relation_data(dataset):\n",
    "    \"\"\"\n",
    "    Prepares data for relation extraction baseline.\n",
    "    Args:\n",
    "        dataset (list): Dataset with relation tuples.\n",
    "    Returns:\n",
    "        list, list: Features (contexts) and labels (relations).\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    labels = []\n",
    "    for sample in dataset:\n",
    "        for relation in sample[\"relation_tuples\"]:\n",
    "            entity1, relation_type, entity2 = relation\n",
    "            context = f\"{entity1} {relation_type} {entity2}\"\n",
    "            contexts.append(context)\n",
    "            labels.append(relation_type)\n",
    "    return contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64c117b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Training ---\n",
    "\n",
    "# Train and evaluate NER model\n",
    "def train_ner_model(train_data, test_data):\n",
    "    # Prepare training and testing data for NER\n",
    "    train_features, train_labels = prepare_ner_data(train_data)\n",
    "    test_features, test_labels = prepare_ner_data(test_data)\n",
    "\n",
    "    # Train CRF model\n",
    "    crf = CRF(algorithm=\"lbfgs\", max_iterations=100)\n",
    "    crf.fit(train_features, train_labels)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = crf.predict(test_features)\n",
    "    print(\"NER Classification Report:\")\n",
    "    print(metrics.flat_classification_report(test_labels, predictions))\n",
    "\n",
    "    return crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9176e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate relation extraction model\n",
    "def train_relation_model(train_data, test_data, multi_class=True):\n",
    "    # Prepare training and testing data for relation extraction\n",
    "    train_contexts, train_labels = prepare_relation_data(train_data)\n",
    "    test_contexts, test_labels = prepare_relation_data(test_data)\n",
    "\n",
    "    # Vectorize contexts\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train = vectorizer.fit_transform(train_contexts)\n",
    "    X_test = vectorizer.transform(test_contexts)\n",
    "\n",
    "    # Train Logistic Regression model\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, train_labels)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(\"Relation Extraction Classification Report:\")\n",
    "    print(classification_report(test_labels, predictions))\n",
    "\n",
    "    return clf, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efb8c444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-Chemical       0.96      0.18      0.30       721\n",
      "   B-Disease       0.85      0.35      0.50       602\n",
      "  I-Chemical       1.00      0.09      0.17       161\n",
      "   I-Disease       0.75      0.34      0.47       362\n",
      "           O       0.92      1.00      0.95     14512\n",
      "\n",
      "    accuracy                           0.91     16358\n",
      "   macro avg       0.90      0.39      0.48     16358\n",
      "weighted avg       0.91      0.91      0.89     16358\n",
      "\n",
      "Relation Extraction Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CID       1.00      1.00      1.00      1892\n",
      "\n",
      "    accuracy                           1.00      1892\n",
      "   macro avg       1.00      1.00      1.00      1892\n",
      "weighted avg       1.00      1.00      1.00      1892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For BC5CDR: Binary Relation Extraction\n",
    "bc5cdr_train = generate_negative_samples(bc5cdr_splits[\"train\"], negative_ratio=1.0)\n",
    "ner_model = train_ner_model(bc5cdr_splits[\"train\"], bc5cdr_splits[\"test\"])\n",
    "relation_model, vectorizer = train_relation_model(bc5cdr_train, bc5cdr_splits[\"test\"], multi_class=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4737806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation Extraction Classification Report:\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "           chem_disease:marker/mechanism       1.00      1.00      1.00      1184\n",
      "                chem_disease:therapeutic       1.00      1.00      1.00      1416\n",
      "              chem_gene:affects^activity       1.00      1.00      1.00        80\n",
      "               chem_gene:affects^binding       1.00      1.00      1.00       488\n",
      "            chem_gene:affects^expression       1.00      1.00      1.00       203\n",
      "          chem_gene:affects^localization       1.00      1.00      1.00       379\n",
      "  chem_gene:affects^metabolic_processing       1.00      1.00      1.00        36\n",
      "             chem_gene:affects^transport       1.00      1.00      1.00       106\n",
      "            chem_gene:decreases^activity       1.00      1.00      1.00      1171\n",
      "          chem_gene:decreases^expression       1.00      1.00      1.00      1347\n",
      "chem_gene:decreases^metabolic_processing       1.00      1.00      1.00       231\n",
      "           chem_gene:decreases^transport       1.00      1.00      1.00        11\n",
      "            chem_gene:increases^activity       1.00      1.00      1.00       753\n",
      "          chem_gene:increases^expression       1.00      1.00      1.00      1463\n",
      "chem_gene:increases^metabolic_processing       1.00      1.00      1.00       571\n",
      "           chem_gene:increases^transport       1.00      1.00      1.00        88\n",
      "           gene_disease:marker/mechanism       1.00      1.00      1.00       602\n",
      "                gene_disease:therapeutic       1.00      1.00      1.00       191\n",
      "\n",
      "                                accuracy                           1.00     10320\n",
      "                               macro avg       1.00      1.00      1.00     10320\n",
      "                            weighted avg       1.00      1.00      1.00     10320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For CHEM_DIS_GENE: Multi-Class Relation Extraction\n",
    "relation_model_multi, vectorizer_multi = train_relation_model(chem_dis_gene_splits[\"train\"], chem_dis_gene_splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ccf8df73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Aspirin affects liver function --> Predicted Relation: CID\n",
      "Context: Aspirin affects hypertension --> Predicted Relation: CID\n"
     ]
    }
   ],
   "source": [
    "# Example real-world biomedical text\n",
    "input_text = \"\"\"\n",
    "The patient was treated with Aspirin for pain relief, but experienced a side effect of nausea. \n",
    "Studies have shown that Aspirin may have an impact on liver function in patients with pre-existing liver diseases.\n",
    "The effect of aspirin on hypertension is also widely discussed in clinical research.\n",
    "\"\"\"\n",
    "\n",
    "# Corrected entity pairs (each tuple should have 3 elements: entity1, relation, entity2)\n",
    "entity_pairs = [\n",
    "    (\"Aspirin\", \"affects\", \"liver function\"),  # Corrected to include \"affects\" as relation and \"liver function\" as entity2\n",
    "    (\"Aspirin\", \"affects\", \"hypertension\")    # Same correction for hypertension\n",
    "]\n",
    "\n",
    "# Create contexts for each pair (now correctly includes 3 elements per tuple)\n",
    "contexts = [f\"{e1} {relation} {e2}\" for e1, relation, e2 in entity_pairs]\n",
    "\n",
    "# Vectorize contexts using the same vectorizer from training\n",
    "X_real = vectorizer.transform(contexts)\n",
    "\n",
    "# Predict using the trained relation extraction model\n",
    "predictions = relation_model.predict(X_real)\n",
    "\n",
    "# Output predictions\n",
    "for context, pred in zip(contexts, predictions):\n",
    "    print(f\"Context: {context} --> Predicted Relation: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1cb90",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "Context: Aspirin affects liver function --> Predicted Relation: chem_disease:therapeutic\n",
    "\n",
    "Context: Aspirin affects hypertension --> Predicted Relation: chem_disease:therapeutic\n",
    "\n",
    "**obviously model trained for RE is overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe913b",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655d6ee",
   "metadata": {},
   "source": [
    "**Dataset Conversion for Transformers:**\n",
    "\n",
    "\n",
    "Transformed the BIO-tagged dataset into a format suitable for Hugging Face’s Transformers library.\n",
    "\n",
    "Used the prepare_ner_dataset_for_transformers function to:\n",
    "Tokenize the text.\n",
    "\n",
    "Align labels with tokenized words using the word_ids function (to handle subword tokenization by the BioBERT tokenizer).\n",
    "\n",
    "Add padding and truncation to ensure consistent input lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba271586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for BioBERT\n",
    "def prepare_ner_dataset_for_transformers(dataset, tokenizer, label_to_id, max_length=128):\n",
    "    \"\"\"\n",
    "    Converts NER dataset to a format suitable for transformer models.\n",
    "    Args:\n",
    "        dataset (list): List of token-label pairs.\n",
    "        tokenizer: Tokenizer from Hugging Face transformers.\n",
    "        label_to_id (dict): Mapping of labels to numeric IDs.\n",
    "        max_length (int): Max sequence length for tokenizer.\n",
    "    Returns:\n",
    "        Dataset: Hugging Face Dataset object for training.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in dataset:\n",
    "        sample_tokens, sample_labels = zip(*sample[\"bio_tags\"])\n",
    "        tokens.append(sample_tokens)\n",
    "        labels.append([label_to_id[label] for label in sample_labels])\n",
    "\n",
    "    encodings = tokenizer(tokens, is_split_into_words=True, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    def align_labels_with_tokens(labels, encodings):\n",
    "        new_labels = []\n",
    "        for i, label in enumerate(labels):\n",
    "            word_ids = encodings.word_ids(batch_index=i)\n",
    "            new_labels.append([-100 if word_id is None else label[word_id] for word_id in word_ids])\n",
    "        return new_labels\n",
    "\n",
    "    encodings[\"labels\"] = align_labels_with_tokens(labels, encodings)\n",
    "    return Dataset.from_dict(encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fced1",
   "metadata": {},
   "source": [
    "**Label Mapping:**\n",
    "\n",
    "\n",
    "Created a mapping from entity labels to IDs (label_to_id) and vice versa (id_to_label) for use in the model.\n",
    "This ensures compatibility between the dataset labels and the model’s expected output.\n",
    "Relation Extraction (RE) Data Preparation\n",
    "Entity Pair Contexts:\n",
    "\n",
    "\n",
    "Extracted sentence-level contexts for each pair of entities with their relation.\n",
    "Used [SEP] as a separator between the two entities in the context to ensure clarity.\n",
    "Example:\n",
    " For the relation (Aspirin, chem_disease:therapeutic, fever), the context was formatted as:\n",
    " \"Aspirin [SEP] fever\"\n",
    "\n",
    "\n",
    "Label Mapping:\n",
    "\n",
    "Created mappings for relation labels (e.g., chem_disease:therapeutic) to IDs (label_to_id) and the reverse (id_to_label).\n",
    "Converted all relation labels in the dataset to integers using label_to_id.\n",
    "Tokenization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64eaaa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label mappings\n",
    "unique_labels = list(set(tag for sample in bc5cdr_splits[\"train\"] for _, tag in sample[\"bio_tags\"]))\n",
    "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331b15b",
   "metadata": {},
   "source": [
    "Tokenized the entity pair contexts using the BioBERT tokenizer.\n",
    "Included truncation, padding, and ensured consistency in sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d47eb93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", num_labels=len(label_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cffc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = prepare_ner_dataset_for_transformers(bc5cdr_splits[\"train\"], tokenizer, label_to_id)\n",
    "test_dataset = prepare_ner_daataset_for_transformers(bc5cdr_splits[\"test\"], tokenizer, label_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af35ae",
   "metadata": {},
   "source": [
    "**Training Configuration:**\n",
    "\n",
    "* Defined training arguments using TrainingArguments:\n",
    "* Batch size: 16\n",
    "* Learning rate: 1e-4 (adjusted for fine-tuning)\n",
    "* Number of epochs: 10\n",
    "* Warmup steps: 1000 (for gradual learning rate increase)\n",
    "* Used a DataCollatorForTokenClassification for padding and batching during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5720913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "\n",
    "# Define data collator and training arguments\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  # Evaluate after every epoch\n",
    "    save_strategy=\"epoch\",  # Save after every epoch\n",
    "    logging_dir=\"./logs\",  # Save logs here\n",
    "    learning_rate=1e-4,  # Lower learning rate\n",
    "    per_device_train_batch_size=16,  # You can try increasing this if you have more memory\n",
    "    per_device_eval_batch_size=16,  # Same as training batch size\n",
    "    num_train_epochs=10,  # Reduce the number of epochs for quicker experimentation\n",
    "    weight_decay=0.02,  # Regularization to prevent overfitting\n",
    "    warmup_steps=1000,  # Gradual learning rate warmup\n",
    "    max_grad_norm=2.0,  # Prevent exploding gradients\n",
    "    save_total_limit=2,  # Only keep 2 checkpoint files\n",
    "    load_best_model_at_end=True,  # Ensure the best model is loaded\n",
    "    metric_for_best_model=\"eval_loss\",  # Track loss for best model\n",
    "    greater_is_better=False,  # Lower loss is better\n",
    "    logging_steps=10,  # Frequency of logging\n",
    "    disable_tqdm=False,  # Set to False to see progress\n",
    "    lr_scheduler_type=\"linear\",  # Learning rate scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7771f35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_11048/633751434.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2d8ae57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.612075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.635500</td>\n",
       "      <td>1.549659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.575500</td>\n",
       "      <td>1.447037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.446600</td>\n",
       "      <td>1.308743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.266700</td>\n",
       "      <td>1.138722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.266700</td>\n",
       "      <td>0.952709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.041000</td>\n",
       "      <td>0.803235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>0.678273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.686300</td>\n",
       "      <td>0.570538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.525100</td>\n",
       "      <td>0.473044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=1.1259742021560668, metrics={'train_runtime': 43.9315, 'train_samples_per_second': 79.67, 'train_steps_per_second': 1.821, 'total_flos': 228640863360000.0, 'train_loss': 1.1259742021560668, 'epoch': 10.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "169f9ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Evaluation Results: {'eval_loss': 0.473043829202652, 'eval_runtime': 0.2045, 'eval_samples_per_second': 366.773, 'eval_steps_per_second': 9.781, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"NER Evaluation Results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cf3695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predicted_labels = predictions.argmax(axis=-1)\n",
    "\n",
    "# Convert IDs back to tags\n",
    "def decode_predictions(predictions, labels, id_to_label):\n",
    "    \"\"\"\n",
    "    Decodes predictions and labels, aligning them by word indices.\n",
    "    Args:\n",
    "        predictions (array): Predicted label IDs.\n",
    "        labels (array): True label IDs.\n",
    "        id_to_label (dict): Mapping of label IDs to label names.\n",
    "    Returns:\n",
    "        list, list: Decoded predictions and labels.\n",
    "    \"\"\"\n",
    "    decoded_preds, decoded_labels = [], []\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        # Ignore padding tokens (-100 in Hugging Face datasets)\n",
    "        aligned_preds = [\n",
    "            id_to_label[p] for p, l in zip(pred, label) if l != -100\n",
    "        ]\n",
    "        aligned_labels = [\n",
    "            id_to_label[l] for p, l in zip(pred, label) if l != -100\n",
    "        ]\n",
    "        decoded_preds.append(aligned_preds)\n",
    "        decoded_labels.append(aligned_labels)\n",
    "    return decoded_preds, decoded_labels\n",
    "\n",
    "\n",
    "decoded_preds, decoded_labels = decode_predictions(predicted_labels, test_dataset[\"labels\"], id_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3cab452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the lists for classification report\n",
    "flat_preds = [pred for sample in decoded_preds for pred in sample]\n",
    "flat_labels = [label for sample in decoded_labels for label in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "264f0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   I-Disease       0.50      0.00      0.01       362\n",
      "  I-Chemical       0.00      0.00      0.00       206\n",
      "   B-Disease       0.60      0.64      0.62       801\n",
      "  B-Chemical       0.70      0.87      0.78      1153\n",
      "           O       0.91      0.94      0.92      6873\n",
      "\n",
      "    accuracy                           0.85      9395\n",
      "   macro avg       0.54      0.49      0.46      9395\n",
      "weighted avg       0.82      0.85      0.82      9395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute and print classification report\n",
    "report = classification_report(\n",
    "    flat_labels,\n",
    "    flat_preds,\n",
    "    labels=list(id_to_label.values()),\n",
    "    zero_division=0\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5429463",
   "metadata": {},
   "source": [
    "**Evaluation:**\n",
    "\n",
    "Evaluated the trained model on the test set using the classification report for BIO-tagging.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "Precision, Recall, and F1-score were reported for each entity type.\n",
    "\n",
    "Observed good performance for B-Chemical and B-Disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef95b9",
   "metadata": {},
   "source": [
    "## Model Fine-Tuning BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb221e",
   "metadata": {},
   "source": [
    "### **NER Model Fine-Tuning**\n",
    "\n",
    "**Model Architecture:**\n",
    "\n",
    "Used AutoModelForTokenClassification from Hugging Face, which appends a classification head to BioBERT for token classification tasks.\n",
    "\n",
    "Configured the model with the number of unique NER labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66b40e94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Fine-Tuning BioBERT for NER\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\") # Load BioBERT tokenizer and model for NER\n",
    "model_ner = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"dmis-lab/biobert-base-cased-v1.1\",\n",
    "    num_labels=len(label_to_id),\n",
    "    ignore_mismatched_sizes=True  # Handles classifier weight mismatch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7793616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"dmis-lab/biobert-base-cased-v1.1\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.47.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_ner.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65404f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare NER dataset\n",
    "train_dataset = prepare_ner_dataset_for_transformers(bc5cdr_splits[\"train\"], tokenizer, label_to_id)\n",
    "test_dataset = prepare_ner_dataset_for_transformers(bc5cdr_splits[\"test\"], tokenizer, label_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bb9c7",
   "metadata": {},
   "source": [
    "**Training Configuration:**\n",
    "\n",
    "* Defined training arguments using TrainingArguments:\n",
    "* Batch size: 8\n",
    "* Learning rate: 2e-5 (adjusted for fine-tuning)\n",
    "* Number of epochs: 3\n",
    "* Saved the best model based on validation loss.\n",
    "* Used a DataCollatorForTokenClassification for padding and batching during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96a4d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args_ner = TrainingArguments(\n",
    "    output_dir=\"./results_ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_ner\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5ac614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Trainer for NER\n",
    "data_collator_ner = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b3be88",
   "metadata": {},
   "source": [
    "**Training:**\n",
    "\n",
    "Fine-tuned BioBERT on the NER training dataset using the Hugging Face Trainer API.\n",
    "\n",
    "Validated the model after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0782ba22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_11048/3597033262.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_ner = Trainer(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer_ner = Trainer(\n",
    "    model=model_ner,\n",
    "    args=training_args_ner,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator_ner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da242e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.669114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.486232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.445746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45, training_loss=0.6643778059217665, metrics={'train_runtime': 16.5669, 'train_samples_per_second': 63.379, 'train_steps_per_second': 2.716, 'total_flos': 68592259008000.0, 'train_loss': 0.6643778059217665, 'epoch': 3.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "trainer_ner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac20717",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db05c53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.44574615359306335,\n",
       " 'eval_runtime': 0.3279,\n",
       " 'eval_samples_per_second': 228.713,\n",
       " 'eval_steps_per_second': 12.198,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_ner.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945da657",
   "metadata": {},
   "source": [
    "### **Relation Extraction (RE) Model Fine-Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2897d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Relation Extraction Dataset\n",
    "def prepare_relation_data(dataset):\n",
    "    \"\"\"\n",
    "    Extracts contexts and labels for relation extraction.\n",
    "    Args:\n",
    "        dataset (list): Dataset containing relation tuples.\n",
    "    Returns:\n",
    "        list, list: Contexts (sentences) and labels (relation types).\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    labels = []\n",
    "    for sample in dataset:\n",
    "        for relation in sample[\"relation_tuples\"]:\n",
    "            entity1, relation_type, entity2 = relation\n",
    "            context = f\"{entity1} [SEP] {entity2}\"  # Use [SEP] for clear distinction\n",
    "            contexts.append(context)\n",
    "            labels.append(relation_type)\n",
    "    return contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06ababeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and testing data\n",
    "train_contexts, train_labels = prepare_relation_data(chem_dis_gene_splits[\"train\"])\n",
    "test_contexts, test_labels = prepare_relation_data(chem_dis_gene_splits[\"test\"])\n",
    "\n",
    "# Step 2: Map Relation Labels to Integers\n",
    "# Create label-to-id and id-to-label mappings\n",
    "unique_labels = list(set(train_labels))\n",
    "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "# Convert labels to integer IDs\n",
    "train_labels = [label_to_id[label] for label in train_labels]\n",
    "test_labels = [label_to_id[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42dca7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Tokenize Relation Data\n",
    "def tokenize_relation_data(contexts, labels, tokenizer, max_length=128):\n",
    "    \"\"\"\n",
    "    Tokenizes contexts and attaches integer labels for sequence classification.\n",
    "    Args:\n",
    "        contexts (list): List of sentences (contexts).\n",
    "        labels (list): Corresponding integer relation labels.\n",
    "        tokenizer: Pretrained tokenizer.\n",
    "        max_length (int): Maximum sequence length.\n",
    "    Returns:\n",
    "        Dataset: Hugging Face Dataset object with tokenized inputs.\n",
    "    \"\"\"\n",
    "    encodings = tokenizer(contexts, truncation=True, padding=True, max_length=max_length)\n",
    "    return Dataset.from_dict({\"input_ids\": encodings[\"input_ids\"], \n",
    "                              \"attention_mask\": encodings[\"attention_mask\"], \n",
    "                              \"labels\": labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee82d6f",
   "metadata": {},
   "source": [
    "**Model Architecture:**\n",
    "\n",
    "Used AutoModelForSequenceClassification for relation classification:\n",
    "BioBERT encoder.\n",
    "\n",
    "Classification head for relation prediction.\n",
    "\n",
    "Configured with the number of unique relation types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3daf5b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load BioBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# Tokenize training and testing data\n",
    "train_data_re = tokenize_relation_data(train_contexts, train_labels, tokenizer)\n",
    "test_data_re = tokenize_relation_data(test_contexts, test_labels, tokenizer)\n",
    "\n",
    "# Step 4: Fine-Tune BioBERT\n",
    "# Load BioBERT model for sequence classification\n",
    "model_re = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"dmis-lab/biobert-base-cased-v1.1\", num_labels=len(label_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c6dc9",
   "metadata": {},
   "source": [
    "**Training Configuration:**\n",
    "\n",
    "* Similar to the NER setup, but adjusted for sequence classification:\n",
    "* Batch size: 16\n",
    "* Learning rate: 1e-5\n",
    "* Number of epochs: 3\n",
    "* Saved the best model based on validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cefcec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args_re = TrainingArguments(\n",
    "    output_dir=\"./results_re\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_re\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad51973",
   "metadata": {},
   "source": [
    "**Training:**\n",
    "\n",
    "Fine-tuned BioBERT for RE using the tokenized entity pair contexts and relation labels.\n",
    "\n",
    "Validated after every epoch to monitor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7abb17fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_11048/109929619.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_re = Trainer(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2397' max='2397' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2397/2397 10:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.668200</td>\n",
       "      <td>2.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>2.515334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>2.663029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Trainer\n",
    "trainer_re = Trainer(\n",
    "    model=model_re,\n",
    "    args=training_args_re,\n",
    "    train_dataset=train_data_re,\n",
    "    eval_dataset=test_data_re,\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "# Train and evaluate the model\n",
    "trainer_re.train()\n",
    "evaluation_results = trainer_re.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522e1fc",
   "metadata": {},
   "source": [
    "**Evaluation:**\n",
    "\n",
    "Used the test set to evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5803f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation Extraction Evaluation Results: {'eval_loss': 2.2711856365203857, 'eval_runtime': 17.2405, 'eval_samples_per_second': 598.59, 'eval_steps_per_second': 12.471, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Output Evaluation Metrics\n",
    "print(\"Relation Extraction Evaluation Results:\", evaluation_results)\n",
    "\n",
    "# Optional: Map back predictions to relation labels\n",
    "predictions = trainer_re.predict(test_data_re)\n",
    "predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "predicted_relations = [id_to_label[pred] for pred in predicted_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28af65db",
   "metadata": {},
   "source": [
    "Mapped predicted labels back to relation types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b121945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predicted Relations: ['chem_disease:marker/mechanism', 'chem_disease:marker/mechanism', 'chem_disease:therapeutic', 'chem_disease:therapeutic', 'chem_disease:therapeutic']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Predicted Relations:\", predicted_relations[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175b61e",
   "metadata": {},
   "source": [
    "Reported metrics including Precision, Recall, and F1-score for each relation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ce9099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.21      0.24      1171\n",
      "           1       0.00      0.00      0.00        88\n",
      "           2       0.41      0.37      0.39       191\n",
      "           3       0.18      0.36      0.24       753\n",
      "           4       0.00      0.00      0.00        80\n",
      "           5       0.00      0.00      0.00       203\n",
      "           6       0.00      0.00      0.00        11\n",
      "           7       0.00      0.00      0.00       106\n",
      "           8       0.57      0.81      0.67      1184\n",
      "           9       0.27      0.13      0.18      1347\n",
      "          10       0.00      0.00      0.00       231\n",
      "          11       0.68      0.60      0.64       602\n",
      "          12       0.00      0.00      0.00        36\n",
      "          13       0.34      0.47      0.40       488\n",
      "          14       0.00      0.00      0.00       379\n",
      "          15       0.23      0.48      0.31      1463\n",
      "          16       0.16      0.06      0.09       571\n",
      "          17       0.73      0.50      0.59      1416\n",
      "\n",
      "    accuracy                           0.36     10320\n",
      "   macro avg       0.21      0.22      0.21     10320\n",
      "weighted avg       0.35      0.36      0.34     10320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels, zero_division=0)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799029f",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "`NER Results`\n",
    "\n",
    "**NER Classification Report:**\n",
    "\n",
    "Good performance for entity categories like B-Chemical and B-Disease.\n",
    "\n",
    "Lower performance for I-Chemical and I-Disease, likely due to data sparsity and sequence alignment issues.\n",
    "\n",
    "**Validation Loss Over Epochs:**\n",
    "Observed a consistent decline in loss, indicating stable training.\n",
    "\n",
    "\n",
    "`RE Results`\n",
    "\n",
    "**Relation Extraction Classification Report:**\n",
    "\n",
    "Strong performance for frequent relations like chem_disease:marker/mechanism and chem_disease:therapeutic.\n",
    "\n",
    "Lower performance for rare relations like chem_gene:increases^transport, indicating the need for more data or augmentation for these classes.\n",
    "\n",
    "**Validation Loss Over Epochs:**\n",
    "\n",
    "Loss decreased over the training epochs, though some overfitting might be indicated due to the small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe416192",
   "metadata": {},
   "source": [
    "## Multi-Task Learning Shared Encoder with Separate Heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73466b35",
   "metadata": {},
   "source": [
    "In this phase, we implemented and evaluated a multi-task learning model leveraging BioBERT and SciBERT for joint training on NER and RE tasks. \n",
    "\n",
    "**Multi-Task Model Design**\n",
    "\n",
    "The MultiTaskModel is designed to share a single encoder while having two separate heads:\n",
    "\n",
    "Encoder: Extracts contextualized representations for tokens and sentences using BioBERT or SciBERT.\n",
    "\n",
    "NER Head: Processes the encoder's output for token-level classification (NER).\n",
    "\n",
    "Relation Extraction (RE) Head: Processes the pooled output of the encoder for sentence-level classification (RE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e8770",
   "metadata": {},
   "source": [
    "## BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f75ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Multi-Task Model\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, encoder_name, num_ner_labels, num_rel_labels):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "        self.ner_head = nn.Linear(self.encoder.config.hidden_size, num_ner_labels)\n",
    "        self.re_head = nn.Linear(self.encoder.config.hidden_size, num_rel_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state  # For NER\n",
    "        pooled_output = outputs.pooler_output  # For Relation Extraction\n",
    "        \n",
    "        ner_logits = self.ner_head(sequence_output)\n",
    "        re_logits = self.re_head(pooled_output)\n",
    "        \n",
    "        return ner_logits, re_logits\n",
    "\n",
    "\n",
    "# Initialize Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c76aa",
   "metadata": {},
   "source": [
    "**Data Preparation**\n",
    "\n",
    "`NER Dataset Preparation`\n",
    "\n",
    "Tokenization:\n",
    "Tokenized text using BioBERT’s tokenizer.\n",
    "Split sentences into tokens and aligned BIO tags to tokens using the word_ids function to handle subword tokenization.\n",
    "\n",
    "Label Mapping:\n",
    "Created a mapping (label_to_id) from BIO tags (O, B-Chemical, I-Chemical, etc.) to integers.\n",
    "Assigned -100 to padding tokens for loss masking during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c676114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare NER Dataset\n",
    "def prepare_ner_dataset(dataset, tokenizer, label_to_id, max_length=128):\n",
    "    \"\"\"\n",
    "    Prepares NER dataset for the multi-task model.\n",
    "    Args:\n",
    "        dataset: Split dataset for NER.\n",
    "        tokenizer: Pretrained tokenizer.\n",
    "        label_to_id: Mapping of BIO tags to IDs.\n",
    "        max_length: Maximum sequence length for tokenization.\n",
    "    Returns:\n",
    "        list: List of tokenized inputs and aligned labels.\n",
    "    \"\"\"\n",
    "    tokenized_data = []\n",
    "    for sample in dataset:\n",
    "        tokens, tags = zip(*sample[\"bio_tags\"])  # Unpack tokens and BIO tags\n",
    "        \n",
    "        tokenized = tokenizer(\n",
    "            list(tokens), truncation=True, padding=\"max_length\", max_length=max_length, is_split_into_words=True\n",
    "        )\n",
    "        \n",
    "        # Align labels with tokenized input using word_ids()\n",
    "        word_ids = tokenized.word_ids()\n",
    "        aligned_labels = [\n",
    "            label_to_id[tags[word_id]] if word_id is not None else -100\n",
    "            for word_id in word_ids\n",
    "        ]\n",
    "        \n",
    "        tokenized[\"labels\"] = aligned_labels\n",
    "        tokenized_data.append(tokenized)\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86123b92",
   "metadata": {},
   "source": [
    "`RE Dataset Preparation`\n",
    "\n",
    "Relation Extraction Contexts:\n",
    "\n",
    "Extracted entity pairs from sentences and created a context string of the form:\n",
    "entity1 [SEP] entity2. This ensures clear separation between the two entities.\n",
    "\n",
    "Tokenization:\n",
    "\n",
    "Tokenized the entity pair contexts with BioBERT’s tokenizer and attached their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f7bbc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Relation Extraction Dataset\n",
    "def prepare_re_dataset(dataset, tokenizer, label_to_id, max_length=128):\n",
    "    \"\"\"\n",
    "    Prepares Relation Extraction dataset for the multi-task model.\n",
    "    Args:\n",
    "        dataset: Split dataset for relation extraction.\n",
    "        tokenizer: Pretrained tokenizer.\n",
    "        label_to_id: Mapping of relation labels to IDs.\n",
    "        max_length: Maximum sequence length for tokenization.\n",
    "    Returns:\n",
    "        list: List of tokenized inputs and labels.\n",
    "    \"\"\"\n",
    "    tokenized_data = []\n",
    "    for sample in dataset:\n",
    "        for relation in sample[\"relation_tuples\"]:\n",
    "            entity1, relation_type, entity2 = relation\n",
    "            context = f\"{entity1} [SEP] {entity2}\"\n",
    "            tokenized = tokenizer(\n",
    "                context, truncation=True, padding=\"max_length\", max_length=max_length\n",
    "            )\n",
    "            # Assign the correct label\n",
    "            if relation_type in label_to_id:\n",
    "                tokenized[\"relation_label\"] = label_to_id[relation_type]\n",
    "                tokenized_data.append(tokenized)\n",
    "            else:\n",
    "                print(f\"Unknown relation type: {relation_type}\")\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd3cdf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relation_types(dataset):\n",
    "    relation_types = set()\n",
    "    for sample in dataset:\n",
    "        for relation in sample[\"relation_tuples\"]:\n",
    "            _, relation_type, _ = relation\n",
    "            relation_types.add(relation_type)\n",
    "    return relation_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765937f",
   "metadata": {},
   "source": [
    "**Multi-Task DataLoader**\n",
    "\n",
    "To feed the model, NER and RE datasets were combined into a single DataLoader. For each batch:\n",
    "\n",
    "NER Data: Input IDs, attention masks, and token-level labels.\n",
    "\n",
    "RE Data: Input IDs, attention masks, and sentence-level relation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e53a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Multi-Task DataLoader\n",
    "def prepare_multi_task_data(train_ner, train_re, tokenizer, batch_size=16):\n",
    "    \"\"\"\n",
    "    Combines NER and relation extraction data into a DataLoader.\n",
    "    Args:\n",
    "        train_ner: Tokenized NER data.\n",
    "        train_re: Tokenized relation extraction data.\n",
    "        tokenizer: Pretrained tokenizer.\n",
    "        batch_size (int): Batch size.\n",
    "    Returns:\n",
    "        DataLoader: DataLoader for training.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    ner_labels = []\n",
    "    re_labels = []\n",
    "\n",
    "    for ner_sample, re_sample in zip(train_ner, train_re):\n",
    "        input_ids.append(ner_sample[\"input_ids\"])\n",
    "        attention_masks.append(ner_sample[\"attention_mask\"])\n",
    "        ner_labels.append(ner_sample[\"labels\"])\n",
    "        re_labels.append(re_sample[\"relation_label\"])\n",
    "\n",
    "    # Convert to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    ner_labels = torch.tensor(ner_labels)\n",
    "    re_labels = torch.tensor(re_labels)\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataset = torch.utils.data.TensorDataset(input_ids, attention_masks, ner_labels, re_labels)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cbe24a",
   "metadata": {},
   "source": [
    "**Training Process**\n",
    "\n",
    "DataLoader Preparation\n",
    "\n",
    "We combined NER and RE data into a single DataLoader:\n",
    "1. Merged tokenized NER and RE datasets.\n",
    "2. Aligned the input features (`input_ids`, `attention_mask`) with task-specific labels:\n",
    "   - `labels_ner` for token-level BIO-tagging.\n",
    "   - `labels_re` for relation classification.\n",
    "\n",
    "**Loss Functions**\n",
    "1. NER Loss:\n",
    "   - Used `CrossEntropyLoss` for token classification.\n",
    "   - Ignored padding tokens (`-100`).\n",
    "2. RE Loss:\n",
    "   - Used `CrossEntropyLoss` for sentence-level classification.\n",
    "3. Total Loss:\n",
    "   - Sum of NER and RE losses to jointly train both tasks.\n",
    "\n",
    "**Optimizer**\n",
    "- Used AdamW with a learning rate of 1e-5 to fine-tune the model.\n",
    "\n",
    "**Training**\n",
    "The model was trained for 20 epochs. During each epoch:\n",
    "1. Forward Pass:\n",
    "   - The input data was passed through the shared encoder and task-specific heads.\n",
    "   - NER logits were computed for each token, and RE logits were computed for each sentence.\n",
    "2. Loss Calculation:\n",
    "   - NER loss and RE loss were calculated separately and summed.\n",
    "3. Backpropagation:\n",
    "   - Gradients were computed for both losses, and the model was updated using AdamW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "899565d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Functions and Optimizer\n",
    "def train_multi_task_model(train_loader, model, num_ner_labels, num_rel_labels, epochs=20, lr=1e-5):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn_ner = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    loss_fn_re = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[0]\n",
    "            attention_mask = batch[1]\n",
    "            labels_ner = batch[2]\n",
    "            labels_re = batch[3]\n",
    "\n",
    "            # Forward pass\n",
    "            ner_logits, re_logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Compute losses\n",
    "            loss_ner = loss_fn_ner(ner_logits.view(-1, num_ner_labels), labels_ner.view(-1))\n",
    "            loss_re = loss_fn_re(re_logits, labels_re)\n",
    "            loss = loss_ner + loss_re\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc521ac",
   "metadata": {},
   "source": [
    "Relation Labels:\n",
    "\n",
    "Created a mapping (relation_label_to_id) for all possible relation types (e.g., chem_disease:therapeutic) to integers.\n",
    "\n",
    "Filtered out unknown or unsupported relation types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8a34f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Splits\n",
    "label_to_id = {label: idx for idx, label in enumerate([\"O\", \"B-Chemical\", \"I-Chemical\", \"B-Disease\", \"I-Disease\"])}\n",
    "\n",
    "# Extract Relation Types\n",
    "train_relation_types = extract_relation_types(chem_dis_gene_splits[\"train\"])\n",
    "test_relation_types = extract_relation_types(chem_dis_gene_splits[\"test\"])\n",
    "all_relation_types = train_relation_types.union(test_relation_types)\n",
    "relation_label_to_id = {relation: idx for idx, relation in enumerate(all_relation_types)}\n",
    "\n",
    "# Prepare NER and RE data\n",
    "train_ner_data = prepare_ner_dataset(bc5cdr_splits[\"train\"], tokenizer, label_to_id)\n",
    "train_re_data = prepare_re_dataset(chem_dis_gene_splits[\"train\"], tokenizer, relation_label_to_id)\n",
    "\n",
    "# Multi-task DataLoader\n",
    "train_loader = prepare_multi_task_data(train_ner_data, train_re_data, tokenizer)\n",
    "\n",
    "# Initialize Multi-Task Model\n",
    "num_ner_labels = len(label_to_id)\n",
    "num_rel_labels = len(relation_label_to_id)\n",
    "multi_task_model = MultiTaskModel(\"dmis-lab/biobert-base-cased-v1.1\", num_ner_labels, num_rel_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c143d3",
   "metadata": {},
   "source": [
    "**Training Loop**\n",
    "\n",
    "The model was trained jointly for both tasks:\n",
    "\n",
    "Loss Functions:\n",
    "* NER: Token-level cross-entropy loss with ignore_index=-100 for padding.\n",
    "* RE: Sentence-level cross-entropy loss.\n",
    "\n",
    "Optimization:\n",
    "* Combined the two losses for joint optimization.\n",
    "* Backpropagation and weight updates were done using AdamW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627ee4d",
   "metadata": {},
   "source": [
    "**Training**\n",
    "\n",
    "The model was trained for 20 epochs. During each epoch:\n",
    "1. Forward Pass:\n",
    "   - The input data was passed through the shared encoder and task-specific heads.\n",
    "   - NER logits were computed for each token, and RE logits were computed for each sentence.\n",
    "2. Loss Calculation:\n",
    "   - NER loss and RE loss were calculated separately and summed.\n",
    "3. Backpropagation:\n",
    "   - Gradients were computed for both losses, and the model was updated using AdamW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b473353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 4.011008273471486\n",
      "Epoch 2/20, Loss: 3.1825105168602685\n",
      "Epoch 3/20, Loss: 2.7407731251283125\n",
      "Epoch 4/20, Loss: 2.470097140832381\n",
      "Epoch 5/20, Loss: 2.3000051270831716\n",
      "Epoch 6/20, Loss: 2.1524507132443516\n",
      "Epoch 7/20, Loss: 2.0401704040440647\n",
      "Epoch 8/20, Loss: 1.8994456312873147\n",
      "Epoch 9/20, Loss: 1.8091457594524731\n",
      "Epoch 10/20, Loss: 1.6897831884297458\n",
      "Epoch 11/20, Loss: 1.603543763810938\n",
      "Epoch 12/20, Loss: 1.5148781483823603\n",
      "Epoch 13/20, Loss: 1.441392102024772\n",
      "Epoch 14/20, Loss: 1.3535548123446377\n",
      "Epoch 15/20, Loss: 1.2864649214527824\n",
      "Epoch 16/20, Loss: 1.2023707682436162\n",
      "Epoch 17/20, Loss: 1.119357924569737\n",
      "Epoch 18/20, Loss: 1.0547196675430646\n",
      "Epoch 19/20, Loss: 0.9597901701927185\n",
      "Epoch 20/20, Loss: 0.8744925829497251\n",
      "CPU times: user 1h 49min 24s, sys: 2min 15s, total: 1h 51min 39s\n",
      "Wall time: 37min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train Multi-Task Model\n",
    "trained_model = train_multi_task_model(train_loader, multi_task_model, num_ner_labels, num_rel_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "064e5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(trained_model.state_dict(), \"multi_task_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0e14910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multi_task_model(test_loader, model, num_ner_labels, num_rel_labels):\n",
    "    model.eval()\n",
    "    ner_true, ner_pred = [], []  # Lists for storing NER ground truth and predictions\n",
    "    re_true, re_pred = [], []  # Lists for storing RE ground truth and predictions\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[0]\n",
    "            attention_mask = batch[1]\n",
    "            labels_ner = batch[2]\n",
    "            labels_re = batch[3]\n",
    "\n",
    "            # Forward pass\n",
    "            ner_logits, re_logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Collect NER predictions\n",
    "            ner_preds = torch.argmax(ner_logits, dim=-1).view(-1).cpu().numpy()\n",
    "            ner_labels = labels_ner.view(-1).cpu().numpy()\n",
    "            ner_true.extend(ner_labels)\n",
    "            ner_pred.extend(ner_preds)\n",
    "\n",
    "            # Collect RE predictions\n",
    "            re_preds = torch.argmax(re_logits, dim=-1).cpu().numpy()\n",
    "            re_labels = labels_re.cpu().numpy()\n",
    "            re_true.extend(re_labels)\n",
    "            re_pred.extend(re_preds)\n",
    "    \n",
    "    # Calculate metrics for NER\n",
    "    ner_report = classification_report(\n",
    "        ner_true, ner_pred, labels=list(range(num_ner_labels)), zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics for Relation Extraction\n",
    "    re_report = classification_report(\n",
    "        re_true, re_pred, labels=list(range(num_rel_labels)), zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(\"NER Evaluation Report:\\n\", ner_report)\n",
    "    print(\"Relation Extraction Evaluation Report:\\n\", re_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "46b9f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Evaluation Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      6873\n",
      "           1       0.82      0.86      0.84      1153\n",
      "           2       0.78      0.37      0.50       206\n",
      "           3       0.74      0.82      0.78       801\n",
      "           4       0.72      0.62      0.66       362\n",
      "\n",
      "   micro avg       0.89      0.91      0.90      9395\n",
      "   macro avg       0.80      0.73      0.75      9395\n",
      "weighted avg       0.89      0.91      0.90      9395\n",
      "\n",
      "Relation Extraction Evaluation Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           3       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           5       0.00      0.00      0.00       0.0\n",
      "           6       0.00      0.00      0.00      12.0\n",
      "           7       0.00      0.00      0.00       0.0\n",
      "           8       0.00      0.00      0.00       0.0\n",
      "           9       0.00      0.00      0.00       0.0\n",
      "          10       0.00      0.00      0.00       0.0\n",
      "          11       0.00      0.00      0.00       0.0\n",
      "          12       0.00      0.00      0.00       0.0\n",
      "          13       0.00      0.00      0.00       0.0\n",
      "          14       0.00      0.00      0.00      63.0\n",
      "          15       0.00      0.00      0.00       0.0\n",
      "          16       0.00      0.00      0.00       0.0\n",
      "          17       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      75.0\n",
      "   macro avg       0.00      0.00      0.00      75.0\n",
      "weighted avg       0.00      0.00      0.00      75.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare test DataLoader\n",
    "test_ner_data = prepare_ner_dataset(bc5cdr_splits[\"test\"], tokenizer, label_to_id)\n",
    "test_re_data = prepare_re_dataset(chem_dis_gene_splits[\"test\"], tokenizer, relation_label_to_id)\n",
    "test_loader = prepare_multi_task_data(test_ner_data, test_re_data, tokenizer)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_multi_task_model(test_loader, trained_model, num_ner_labels, num_rel_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b98d34",
   "metadata": {},
   "source": [
    "**NER Evaluation**\n",
    "\n",
    "* The model achieved high performance for B-Chemical and B-Disease categories, indicating that the shared encoder effectively learned biomedical entities.\n",
    "\n",
    "* Performance for I-Chemical and I-Disease was slightly lower due to the imbalance and sparsity of these labels in the dataset.\n",
    "\n",
    "**RE Evaluation**\n",
    "\n",
    "* The RE task faced challenges, with low precision and recall across most relation types.\n",
    "\n",
    "* The poor performance suggests that the RE head struggled to learn effectively, potentially due to:\n",
    "Class imbalance in the RE dataset.\n",
    "\n",
    "* Insufficient shared features for relation classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3164fd3",
   "metadata": {},
   "source": [
    "## SciBert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9771a6",
   "metadata": {},
   "source": [
    "**Model Architecture**\n",
    "\n",
    "**SciBERT-Based Multi-Task Model**\n",
    "\n",
    "We designed the `MultiTaskModelSciBERT` class with:\n",
    "1. Encoder:\n",
    "   - A shared SciBERT encoder (`allenai/scibert_scivocab_cased`), pretrained on scientific text.\n",
    "2. NER Head:\n",
    "   - A linear layer for token-level classification. It predicts BIO tags (`B-Chemical`, `I-Disease`, etc.).\n",
    "3. RE Head:\n",
    "   - A linear layer for sentence-level classification. It predicts relation types (e.g., `chem_disease:therapeutic`).\n",
    "\n",
    "**Forward Pass:**\n",
    "- Inputs: Tokenized text and attention masks.\n",
    "- Outputs:\n",
    "  1. NER Logits: Token-level predictions from the encoder's `last_hidden_state`.\n",
    "  2. RE Logits: Sentence-level predictions from the encoder's `pooler_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7475b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Multi-Task Model\n",
    "class MultiTaskModelSciBERT(nn.Module):\n",
    "    def __init__(self, encoder_name, num_ner_labels, num_rel_labels):\n",
    "        super(MultiTaskModelSciBERT, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "        self.ner_head = nn.Linear(self.encoder.config.hidden_size, num_ner_labels)\n",
    "        self.re_head = nn.Linear(self.encoder.config.hidden_size, num_rel_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state  # For NER\n",
    "        pooled_output = outputs.pooler_output  # For Relation Extraction\n",
    "        \n",
    "        ner_logits = self.ner_head(sequence_output)\n",
    "        re_logits = self.re_head(pooled_output)\n",
    "        \n",
    "        return ner_logits, re_logits\n",
    "\n",
    "\n",
    "# Initialize SciBERT Tokenizer\n",
    "tokenizer_sci = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce343f",
   "metadata": {},
   "source": [
    "**Dataset Preparation**\n",
    "\n",
    "**NER Dataset**\n",
    "1. BIO-Tagged Tokens:\n",
    "   - Tokens and corresponding BIO tags (`O`, `B-Chemical`, etc.) were extracted from the BC5CDR dataset.\n",
    "2. Tokenization:\n",
    "   - Text was tokenized using the SciBERT tokenizer.\n",
    "   - Tags were aligned with subword tokens using the `word_ids()` function.\n",
    "3. Labels:\n",
    "   - A mapping (`label_to_id`) was created to convert BIO tags into numeric IDs.\n",
    "   - Padding tokens were assigned a label of `-100` to ignore them during loss calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb382334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare NER Dataset\n",
    "def prepare_ner_dataset(dataset, tokenizer, label_to_id, max_length=128):\n",
    "    tokenized_data = []\n",
    "    for sample in dataset:\n",
    "        tokens, tags = zip(*sample[\"bio_tags\"])  # Unpack tokens and BIO tags\n",
    "        \n",
    "        tokenized = tokenizer(\n",
    "            list(tokens), truncation=True, padding=\"max_length\", max_length=max_length, is_split_into_words=True\n",
    "        )\n",
    "        \n",
    "        # Align labels with tokenized input using word_ids()\n",
    "        word_ids = tokenized.word_ids()\n",
    "        aligned_labels = [\n",
    "            label_to_id[tags[word_id]] if word_id is not None else -100\n",
    "            for word_id in word_ids\n",
    "        ]\n",
    "        \n",
    "        tokenized[\"labels\"] = aligned_labels\n",
    "        tokenized_data.append(tokenized)\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1582933",
   "metadata": {},
   "source": [
    "**Relation Extraction Dataset**\n",
    "1. Entity Pairs:\n",
    "   - Relations were extracted as entity pairs (e.g., `entity1` and `entity2`) from the CHEM_DIS_GENE dataset.\n",
    "   - A context string was created for each pair:  \n",
    "     `entity1 [SEP] entity2`.\n",
    "2. Labels:\n",
    "   - Relations were mapped to numeric IDs using a dictionary (`relation_label_to_id`).\n",
    "   - Only valid relation types were included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43522873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Relation Extraction Dataset\n",
    "def prepare_re_dataset(dataset, tokenizer, label_to_id, max_length=128):\n",
    "    tokenized_data = []\n",
    "    for sample in dataset:\n",
    "        for relation in sample[\"relation_tuples\"]:\n",
    "            entity1, relation_type, entity2 = relation\n",
    "            context = f\"{entity1} [SEP] {entity2}\"\n",
    "            tokenized = tokenizer(\n",
    "                context, truncation=True, padding=\"max_length\", max_length=max_length\n",
    "            )\n",
    "            if relation_type in label_to_id:\n",
    "                tokenized[\"relation_label\"] = label_to_id[relation_type]\n",
    "                tokenized_data.append(tokenized)\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c14ff1",
   "metadata": {},
   "source": [
    "**3. Multi-Task DataLoader**\n",
    "\n",
    "We prepared a combined DataLoader for both tasks:\n",
    "1. NER Features:\n",
    "   - `input_ids`, `attention_mask`, and token-level `labels` for BIO tagging.\n",
    "2. RE Features:\n",
    "   - `relation_label` for sentence-level classification.\n",
    "3. Tensors:\n",
    "   - Converted features to PyTorch tensors and combined them into a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ebbafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Multi-Task DataLoader\n",
    "def prepare_multi_task_data(train_ner, train_re, tokenizer, batch_size=16):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    ner_labels = []\n",
    "    re_labels = []\n",
    "\n",
    "    for ner_sample, re_sample in zip(train_ner, train_re):\n",
    "        input_ids.append(ner_sample[\"input_ids\"])\n",
    "        attention_masks.append(ner_sample[\"attention_mask\"])\n",
    "        ner_labels.append(ner_sample[\"labels\"])\n",
    "        re_labels.append(re_sample[\"relation_label\"])\n",
    "\n",
    "    # Convert to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    ner_labels = torch.tensor(ner_labels)\n",
    "    re_labels = torch.tensor(re_labels)\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataset = torch.utils.data.TensorDataset(input_ids, attention_masks, ner_labels, re_labels)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6fae8",
   "metadata": {},
   "source": [
    "\n",
    "**Training Loop**\n",
    "\n",
    "**Loss Functions**\n",
    "\n",
    "1. NER Loss:\n",
    "   - Used `CrossEntropyLoss`, ignoring padding tokens (`-100`).\n",
    "2. RE Loss:\n",
    "   - Used `CrossEntropyLoss` for multi-class classification.\n",
    "3. Total Loss:\n",
    "   - Combined the NER and RE losses.\n",
    "\n",
    "**Optimization**\n",
    "- Used AdamW optimizer with a learning rate of `2e-5`.\n",
    "\n",
    "**Epochs**\n",
    "The model was trained for 20 epochs. For each epoch:\n",
    "1. Forward Pass:\n",
    "   - Input data was passed through the shared encoder.\n",
    "   - NER and RE logits were computed by task-specific heads.\n",
    "2. Loss Calculation:\n",
    "   - NER loss was computed over token-level predictions.\n",
    "   - RE loss was computed over sentence-level predictions.\n",
    "   - Total loss was backpropagated, and the model parameters were updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "327b8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Loop\n",
    "def train_multi_task_model_sci(train_loader, model, num_ner_labels, num_rel_labels, epochs=20, lr=2e-5):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn_ner = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    loss_fn_re = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[0]\n",
    "            attention_mask = batch[1]\n",
    "            labels_ner = batch[2]\n",
    "            labels_re = batch[3]\n",
    "\n",
    "            # Forward pass\n",
    "            ner_logits, re_logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Compute losses\n",
    "            loss_ner = loss_fn_ner(ner_logits.view(-1, num_ner_labels), labels_ner.view(-1))\n",
    "            loss_re = loss_fn_re(re_logits, labels_re)\n",
    "            loss = loss_ner + loss_re\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1662cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Relation Types\n",
    "def extract_relation_types(dataset):\n",
    "    relation_types = set()\n",
    "    for sample in dataset:\n",
    "        for relation in sample[\"relation_tuples\"]:\n",
    "            _, relation_type, _ = relation\n",
    "            relation_types.add(relation_type)\n",
    "    return relation_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9ae8dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Splits and Label Mappings\n",
    "label_to_id = {label: idx for idx, label in enumerate([\"O\", \"B-Chemical\", \"I-Chemical\", \"B-Disease\", \"I-Disease\"])}\n",
    "\n",
    "# Extract Relation Types\n",
    "train_relation_types = extract_relation_types(chem_dis_gene_splits[\"train\"])\n",
    "test_relation_types = extract_relation_types(chem_dis_gene_splits[\"test\"])\n",
    "all_relation_types = train_relation_types.union(test_relation_types)\n",
    "relation_label_to_id = {relation: idx for idx, relation in enumerate(all_relation_types)}\n",
    "\n",
    "# Prepare NER and RE data\n",
    "train_ner_data = prepare_ner_dataset(bc5cdr_splits[\"train\"], tokenizer_sci, label_to_id)\n",
    "train_re_data = prepare_re_dataset(chem_dis_gene_splits[\"train\"], tokenizer_sci, relation_label_to_id)\n",
    "\n",
    "# Multi-task DataLoader\n",
    "train_loader = prepare_multi_task_data(train_ner_data, train_re_data, tokenizer_sci)\n",
    "\n",
    "# Initialize Multi-Task Model with SciBERT\n",
    "num_ner_labels = len(label_to_id)\n",
    "num_rel_labels = len(relation_label_to_id)\n",
    "multi_task_model_sci = MultiTaskModelSciBERT(\"allenai/scibert_scivocab_cased\", num_ner_labels, num_rel_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d14517b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pperla/.conda/envs/nlp_assignment/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 2.9984978437423706\n",
      "Epoch 2/20, Loss: 2.336603283882141\n",
      "Epoch 3/20, Loss: 2.1355469551953403\n",
      "Epoch 4/20, Loss: 1.9923291585662148\n",
      "Epoch 5/20, Loss: 1.8002874038436196\n",
      "Epoch 6/20, Loss: 1.615173946727406\n",
      "Epoch 7/20, Loss: 1.2954885471950879\n",
      "Epoch 8/20, Loss: 0.959556823427027\n",
      "Epoch 9/20, Loss: 0.7184644869782708\n",
      "Epoch 10/20, Loss: 0.5544729137962515\n",
      "Epoch 11/20, Loss: 0.4517537362196229\n",
      "Epoch 12/20, Loss: 0.3765248168598522\n",
      "Epoch 13/20, Loss: 0.298906261948022\n",
      "Epoch 14/20, Loss: 0.22824622758410193\n",
      "Epoch 15/20, Loss: 0.1923516792329875\n",
      "Epoch 16/20, Loss: 0.1538152742114934\n",
      "Epoch 17/20, Loss: 0.1244105256416581\n",
      "Epoch 18/20, Loss: 0.10334610668095676\n",
      "Epoch 19/20, Loss: 0.09133919277651743\n",
      "Epoch 20/20, Loss: 0.09462589431892741\n",
      "CPU times: user 1h 47min 47s, sys: 1min 41s, total: 1h 49min 28s\n",
      "Wall time: 36min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train Multi-Task Model\n",
    "trained_model_sci = train_multi_task_model_sci(train_loader, multi_task_model_sci, num_ner_labels, num_rel_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bdcffcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(trained_model_sci.state_dict(), \"multi_task_model_sci_9.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf8d0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multi_task_model(test_loader, model, num_ner_labels, num_rel_labels, label_to_id, relation_label_to_id):\n",
    "    \"\"\"\n",
    "    Evaluate a multi-task model for NER and relation extraction.\n",
    "    Args:\n",
    "        test_loader: DataLoader for the test set.\n",
    "        model: Trained multi-task model.\n",
    "        num_ner_labels: Number of NER labels.\n",
    "        num_rel_labels: Number of relation labels.\n",
    "        label_to_id: Mapping of BIO tags to IDs.\n",
    "        relation_label_to_id: Mapping of relation types to IDs.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ner_true = []\n",
    "    ner_pred = []\n",
    "    re_true = []\n",
    "    re_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[0]\n",
    "            attention_mask = batch[1]\n",
    "            labels_ner = batch[2]\n",
    "            labels_re = batch[3]\n",
    "\n",
    "            # Forward pass\n",
    "            ner_logits, re_logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Collect NER predictions\n",
    "            ner_preds = torch.argmax(ner_logits, dim=-1).view(-1)\n",
    "            ner_labels = labels_ner.view(-1)\n",
    "            ner_true.extend(ner_labels.cpu().numpy())\n",
    "            ner_pred.extend(ner_preds.cpu().numpy())\n",
    "\n",
    "            # Collect RE predictions\n",
    "            re_preds = torch.argmax(re_logits, dim=-1)\n",
    "            re_true.extend(labels_re.cpu().numpy())\n",
    "            re_pred.extend(re_preds.cpu().numpy())\n",
    "    \n",
    "    # Decode labels for NER\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    ner_true_decoded = [id_to_label.get(label, \"O\") for label in ner_true]\n",
    "    ner_pred_decoded = [id_to_label.get(label, \"O\") for label in ner_pred]\n",
    "\n",
    "    # Decode labels for RE\n",
    "    id_to_relation = {v: k for k, v in relation_label_to_id.items()}\n",
    "    re_true_decoded = [id_to_relation[label] for label in re_true]\n",
    "    re_pred_decoded = [id_to_relation[label] for label in re_pred]\n",
    "\n",
    "    # NER Metrics\n",
    "    ner_report = classification_report(\n",
    "        ner_true_decoded, ner_pred_decoded, zero_division=0\n",
    "    )\n",
    "    print(\"NER Evaluation Report:\\n\", ner_report)\n",
    "\n",
    "    # Relation Extraction Metrics\n",
    "    re_report = classification_report(\n",
    "        re_true_decoded, re_pred_decoded, zero_division=0\n",
    "    )\n",
    "    print(\"Relation Extraction Evaluation Report:\\n\", re_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "737a6839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Evaluation Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  B-Chemical       0.89      0.87      0.88      1004\n",
      "   B-Disease       0.77      0.79      0.78       523\n",
      "  I-Chemical       0.70      0.52      0.60       191\n",
      "   I-Disease       0.65      0.62      0.63       275\n",
      "           O       0.96      0.97      0.97      7607\n",
      "\n",
      "    accuracy                           0.93      9600\n",
      "   macro avg       0.80      0.76      0.77      9600\n",
      "weighted avg       0.93      0.93      0.93      9600\n",
      "\n",
      "Relation Extraction Evaluation Report:\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "           chem_disease:marker/mechanism       0.00      0.00      0.00         0\n",
      "                chem_disease:therapeutic       0.00      0.00      0.00        12\n",
      "          chem_gene:decreases^expression       1.00      0.08      0.15        63\n",
      "            chem_gene:increases^activity       0.00      0.00      0.00         0\n",
      "          chem_gene:increases^expression       0.00      0.00      0.00         0\n",
      "chem_gene:increases^metabolic_processing       0.00      0.00      0.00         0\n",
      "           gene_disease:marker/mechanism       0.00      0.00      0.00         0\n",
      "\n",
      "                                accuracy                           0.07        75\n",
      "                               macro avg       0.14      0.01      0.02        75\n",
      "                            weighted avg       0.84      0.07      0.12        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare test DataLoader\n",
    "test_ner_data = prepare_ner_dataset(bc5cdr_splits[\"test\"], tokenizer_sci, label_to_id)\n",
    "test_re_data = prepare_re_dataset(chem_dis_gene_splits[\"test\"], tokenizer_sci, relation_label_to_id)\n",
    "test_loader = prepare_multi_task_data(test_ner_data, test_re_data, tokenizer_sci)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_multi_task_model(test_loader, trained_model_sci, num_ner_labels, num_rel_labels, label_to_id, relation_label_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44a80e",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "**NER Performance**\n",
    "\n",
    "SciBERT performed well on NER, achieving high precision, recall, and F1 scores for common labels like `B-Chemical` and `B-Disease`.\n",
    "\n",
    "**Accuracy:** 93%  \n",
    "**Weighted Avg F1-Score:** 93%\n",
    "\n",
    "**RE Performance**\n",
    "\n",
    "The RE task faced challenges, with low performance across all relation types. This was likely due to:\n",
    "- Class imbalance in the dataset.\n",
    "- Limited training data for rare relation types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17932f5",
   "metadata": {},
   "source": [
    "## Real World Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c286d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Acetaminophen is used to treat mild to moderate pain and fever. It is associated with liver damage if taken in high doses.\n",
    "Patients with hepatitis should avoid its usage.\"\"\"\n",
    "\n",
    "#Patient Medical Records:\n",
    "input_text_2 = \"\"\"The patient, a 45-year-old male, presented with complaints of persistent chest pain radiating to the left arm, exacerbated by physical activity, and relieved by rest. \n",
    "Past medical history includes hypertension and type 2 diabetes. No history of smoking or alcohol consumption was noted.\"\"\"\n",
    "\n",
    "#Pathology Reports:\n",
    "input_text_3 = \"\"\"Biopsy of the left breast mass reveals infiltrating ductal carcinoma, Grade II, with positive hormone receptor status. \n",
    "Margins are free of malignancy.\"\"\"\n",
    "\n",
    "#Pharmacovigilance Records:\n",
    "input_text_4 = \"\"\"A 30-year-old female reported severe dizziness and rash following the administration of drug X. \n",
    "Symptoms appeared within 1 hour of ingestion and resolved after discontinuation of the drug.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453fb20",
   "metadata": {},
   "source": [
    "Input text extracted from chatGPT: https://chatgpt.com/share/674f841f-69a0-800b-8844-0977a23bfd55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "75bee5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize input text\n",
    "tokenizer_sci = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_cased\")\n",
    "\n",
    "# Tokenize text\n",
    "inputs = tokenizer_sci(\n",
    "    input_text.strip().split(), #input_text, input_text_2, input_text_3, input_text_4\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    is_split_into_words=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aa06b083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/scratch/local/ipykernel_11048/1387161143.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_sci.load_state_dict(torch.load(\"multi_task_model_sci.pth\")) #with 4% loss @ 93% acc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiTaskModelSciBERT(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31116, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (ner_head): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (re_head): Linear(in_features=768, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model with the correct number of NER and RE labels\n",
    "model_sci = MultiTaskModelSciBERT(\n",
    "    \"allenai/scibert_scivocab_cased\",\n",
    "    num_ner_labels=len(label_to_id),  # Same as training\n",
    "    num_rel_labels=len(relation_label_to_id),  # Same as training\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "model_sci.load_state_dict(torch.load(\"multi_task_model_sci.pth\")) #with 4% loss @ 93% acc\n",
    "#model_sci.load_state_dict(torch.load(\"multi_task_model_sci_9.pth\")) #with 9.4% loss @ 93% acc\n",
    "\n",
    "model_sci.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "32a6b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the model\n",
    "with torch.no_grad():\n",
    "    ner_logits, _ = model_sci(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "# Decode predictions\n",
    "ner_preds = torch.argmax(ner_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8d475144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acet: B-Chemical\n",
      "##amino: B-Chemical\n",
      "##phen: B-Chemical\n",
      "is: O\n",
      "used: O\n",
      "to: O\n",
      "treat: O\n",
      "mild: O\n",
      "to: O\n",
      "moderate: O\n",
      "pain: B-Disease\n",
      "and: O\n",
      "fever: B-Disease\n",
      ".: O\n",
      "it: O\n",
      "is: O\n",
      "associated: O\n",
      "with: O\n",
      "liver: B-Disease\n",
      "damage: I-Disease\n",
      "if: O\n",
      "taken: O\n",
      "in: O\n",
      "high: O\n",
      "doses: O\n",
      ".: O\n",
      "patients: O\n",
      "with: O\n",
      "hepatitis: B-Disease\n",
      "should: O\n",
      "avoid: O\n",
      "its: O\n",
      "usage: O\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from label IDs to BIO tags\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "# Decode predictions\n",
    "decoded_tags = [id_to_label[label_id] for label_id in ner_preds[0].tolist()]\n",
    "\n",
    "# Map tokens to tags\n",
    "tokens = tokenizer_sci.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "result = list(zip(tokens, decoded_tags))\n",
    "\n",
    "# Filter out special tokens ([CLS], [SEP], [PAD])\n",
    "result = [(token, tag) for token, tag in result if token not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]]\n",
    "\n",
    "# Display results\n",
    "for token, tag in result:\n",
    "    print(f\"{token}: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "53c19b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities: {'Chemical': ['acet', '##amino', '##phen'], 'Disease': ['pain', 'fever', 'liver', 'damage', 'hepatitis']}\n"
     ]
    }
   ],
   "source": [
    "# Post-process results\n",
    "extracted_entities = {\n",
    "    \"Chemical\": [],\n",
    "    \"Disease\": [],\n",
    "}\n",
    "\n",
    "for token, tag in result:\n",
    "    if tag.startswith(\"B-\") or tag.startswith(\"I-\"):\n",
    "        entity_type = tag.split(\"-\")[1]\n",
    "        extracted_entities[entity_type].append(token)\n",
    "\n",
    "print(\"Extracted Entities:\", extracted_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "57f6a2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to SciBert_ner_predictions.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Combine all information into a dictionary\n",
    "output_data = {\n",
    "    \"input_text\": input_text,\n",
    "    \"predictions\": [{\"token\": token, \"tag\": tag} for token, tag in result],\n",
    "    \"extracted_entities\": extracted_entities,\n",
    "}\n",
    "\n",
    "# Save the output to a JSON file\n",
    "output_file = \"SciBert_ner_predictions.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(output_data, f, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ade3a",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "1. **Dataset Research**:\n",
    "    - [BC5CDR](https://huggingface.co/datasets/bigbio/bc5cdr).\n",
    "    - [CHEM_DIS_GENE](https://huggingface.co/datasets/bigbio/chem_dis_gene).\n",
    "\n",
    "2. **Papers for Reference**:\n",
    "\n",
    "    Papers on biomedical relation extraction using BERT-based and GPT-based models:\n",
    "    - [BioBERT](https://pubmed.ncbi.nlm.nih.gov/31408207/): Focused on Named Entity Recognition (NER) and Relation Extraction (RE) in biomedical texts.\n",
    "    - [SciBERT](https://aclanthology.org/D19-1371/): Domain-specific embeddings for biomedical tasks.\n",
    "\n",
    "3. **MeSH Browser:** \n",
    "    - You can explore the official MeSH terms using the [MeSH Browser](https://meshb.nlm.nih.gov/search).\n",
    "    \n",
    "    \n",
    "    - [MeSH Base URL](https://id.nlm.nih.gov/mesh/lookup/term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9cd5e",
   "metadata": {},
   "source": [
    "## Future Work:\n",
    "\n",
    "1. **Implement Data Augmentation** \n",
    "\n",
    "2. **Include Gene entity In NER Tasks**\n",
    "\n",
    "3. **⁠⁠Train on Large Language Models**\n",
    "\n",
    "4. ⁠⁠**Replicate a existing paper**\n",
    "\n",
    "5. ⁠⁠**Train with different models like Mamba/Jamba**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60a04ef",
   "metadata": {},
   "source": [
    "### Team Setup\n",
    "\n",
    "\n",
    "| **Team Member**   | **Responsibilities**                                                                 |\n",
    "|-------------------|--------------------------------------------------------------------------------------|\n",
    "| **Aziz** |  Data preprocessing, fine-tuning BioBert for RE.                           |\n",
    "| **Pratul C Perla** | Data preprocessing, baseline model setup, NER tasks, Evaluation.                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f3e3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp_assignment]",
   "language": "python",
   "name": "conda-env-.conda-nlp_assignment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
