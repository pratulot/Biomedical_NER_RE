{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4bf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d6c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NER BIO labels and mapping\n",
    "label_to_id = {\n",
    "    \"O\": 0,\n",
    "    \"B-Chemical\": 1,\n",
    "    \"I-Chemical\": 2,\n",
    "    \"B-Disease\": 3,\n",
    "    \"I-Disease\": 4,\n",
    "}\n",
    "\n",
    "# Define relation types and mapping\n",
    "relation_label_to_id = {\n",
    "    \"CID\": 0,\n",
    "    \"no_relation\": 1,\n",
    "}\n",
    "\n",
    "relation_label_to_id = {\n",
    "    \"chem_disease:marker/mechanism\": 0,\n",
    "    \"chem_disease:therapeutic\": 1,\n",
    "    \"chem_gene:affects^activity\": 2,\n",
    "    \"chem_gene:affects^binding\": 3,\n",
    "    \"chem_gene:affects^expression\": 4,\n",
    "    \"chem_gene:affects^localization\": 5,\n",
    "    \"chem_gene:affects^metabolic_processing\": 6,\n",
    "    \"chem_gene:affects^transport\": 7,\n",
    "    \"chem_gene:decreases^activity\": 8,\n",
    "    \"chem_gene:decreases^expression\": 9,\n",
    "    \"chem_gene:decreases^metabolic_processing\": 10,\n",
    "    \"chem_gene:decreases^transport\": 11,\n",
    "    \"chem_gene:increases^activity\": 12,\n",
    "    \"chem_gene:increases^expression\": 13,\n",
    "    \"chem_gene:increases^metabolic_processing\": 14,\n",
    "    \"chem_gene:increases^transport\": 15,\n",
    "    \"gene_disease:marker/mechanism\": 16,\n",
    "    \"gene_disease:therapeutic\": 17,\n",
    "}\n",
    "num_rel_labels = len(relation_label_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2043a",
   "metadata": {},
   "source": [
    "## Load Your NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9e98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModelSciBERT(torch.nn.Module):\n",
    "    def __init__(self, encoder_name, num_ner_labels, num_rel_labels):\n",
    "        super(MultiTaskModelSciBERT, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "        self.ner_head = torch.nn.Linear(self.encoder.config.hidden_size, num_ner_labels)\n",
    "        self.re_head = torch.nn.Linear(self.encoder.config.hidden_size, num_rel_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state  # For NER\n",
    "        pooled_output = outputs.pooler_output  # For Relation Extraction\n",
    "        ner_logits = self.ner_head(sequence_output)\n",
    "        re_logits = self.re_head(pooled_output)\n",
    "        return ner_logits, re_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a5ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model for NER\n",
    "tokenizer_ner = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_cased\")\n",
    "ner_model = MultiTaskModelSciBERT(\n",
    "    \"allenai/scibert_scivocab_cased\",\n",
    "    num_ner_labels=len(label_to_id),  # Number of NER labels\n",
    "    num_rel_labels=len(relation_label_to_id)  # Number of RE labels\n",
    ")\n",
    "ner_model.load_state_dict(torch.load(\"/data/user/pperla/ondemand/NLP Project/multi_task_model_sci.pth\"))\n",
    "ner_model.eval()\n",
    "\n",
    "# Define label mappings\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b169f1e",
   "metadata": {},
   "source": [
    "## Load  RE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb0863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_tokenizer = AutoTokenizer.from_pretrained(\"/data/user/pperla/ondemand/NLP Project/Aziz/re_tokenizer\")\n",
    "re_model = AutoModelForSequenceClassification.from_pretrained(\"/data/user/pperla/ondemand/NLP Project/Aziz/re_model\")\n",
    "re_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a98536",
   "metadata": {},
   "source": [
    "## NER Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56a6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(input_text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer_ner(\n",
    "        input_text.strip().split(),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    # Predict with NER model\n",
    "    with torch.no_grad():\n",
    "        ner_logits, _ = ner_model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "    # Decode predictions\n",
    "    ner_preds = torch.argmax(ner_logits, dim=-1)\n",
    "    tokens = tokenizer_ner.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    decoded_tags = [id_to_label[label_id] for label_id in ner_preds[0].tolist()]\n",
    "\n",
    "    # Map tokens to tags\n",
    "    result = list(zip(tokens, decoded_tags))\n",
    "    result = [(token, tag) for token, tag in result if token not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]]\n",
    "\n",
    "    # Extract entities\n",
    "    extracted_entities = {\"Chemical\": [], \"Disease\": []}\n",
    "    for token, tag in result:\n",
    "        if tag.startswith(\"B-\") or tag.startswith(\"I-\"):\n",
    "            entity_type = tag.split(\"-\")[1]\n",
    "            extracted_entities[entity_type].append(token)\n",
    "\n",
    "    return extracted_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3769d58",
   "metadata": {},
   "source": [
    "## RE Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad294144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_relations(text, entities, re_model, re_tokenizer):\n",
    "    predictions = []\n",
    "    # Generate all pairs of entities\n",
    "    chemicals = entities[\"Chemical\"]\n",
    "    diseases = entities[\"Disease\"]\n",
    "\n",
    "    for chemical in chemicals:\n",
    "        for disease in diseases:\n",
    "            # Format text for RE model\n",
    "            modified_text = text.replace(chemical, f\"[CHEM] {chemical} [/CHEM]\")\n",
    "            modified_text = modified_text.replace(disease, f\"[DISEASE] {disease} [/DISEASE]\")\n",
    "\n",
    "            # Tokenize and predict\n",
    "            inputs = re_tokenizer(modified_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                outputs = re_model(**inputs)\n",
    "                logits = outputs.logits\n",
    "                prediction = logits.argmax(dim=-1).item()\n",
    "\n",
    "            # Append prediction\n",
    "            relation = \"CID\" if prediction == 1 else \"no relation\"\n",
    "            predictions.append({\"chemical\": chemical, \"disease\": disease, \"relation\": relation})\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d754e6c",
   "metadata": {},
   "source": [
    "## Full Integration Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb9e7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_pipeline(input_text):\n",
    "    # Step 1: NER - Extract entities\n",
    "    entities = predict_entities(input_text)\n",
    "    print(\"Extracted Entities:\", entities)\n",
    "\n",
    "    # Step 2: RE - Predict relations\n",
    "    relations = predict_relations(input_text, entities, re_model, re_tokenizer)\n",
    "    print(\"Predicted Relations:\", relations)\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    output_data = {\n",
    "        \"input_text\": input_text,\n",
    "        \"extracted_entities\": entities,\n",
    "        \"predicted_relations\": relations,\n",
    "    }\n",
    "    output_file = \"/data/user/pperla/ondemand/NLP Project/integrated_results.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd149802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities: {'Chemical': ['acet', '##amino', '##phen'], 'Disease': ['pain', 'fever', 'liver', 'damage', 'hepatitis']}\n",
      "Predicted Relations: [{'chemical': 'acet', 'disease': 'pain', 'relation': 'no relation'}, {'chemical': 'acet', 'disease': 'fever', 'relation': 'no relation'}, {'chemical': 'acet', 'disease': 'liver', 'relation': 'no relation'}, {'chemical': 'acet', 'disease': 'damage', 'relation': 'no relation'}, {'chemical': 'acet', 'disease': 'hepatitis', 'relation': 'no relation'}, {'chemical': '##amino', 'disease': 'pain', 'relation': 'no relation'}, {'chemical': '##amino', 'disease': 'fever', 'relation': 'no relation'}, {'chemical': '##amino', 'disease': 'liver', 'relation': 'no relation'}, {'chemical': '##amino', 'disease': 'damage', 'relation': 'no relation'}, {'chemical': '##amino', 'disease': 'hepatitis', 'relation': 'no relation'}, {'chemical': '##phen', 'disease': 'pain', 'relation': 'no relation'}, {'chemical': '##phen', 'disease': 'fever', 'relation': 'no relation'}, {'chemical': '##phen', 'disease': 'liver', 'relation': 'no relation'}, {'chemical': '##phen', 'disease': 'damage', 'relation': 'no relation'}, {'chemical': '##phen', 'disease': 'hepatitis', 'relation': 'no relation'}]\n",
      "Results saved to /data/user/pperla/ondemand/NLP Project/integrated_results.json\n"
     ]
    }
   ],
   "source": [
    "# **Step 6: Run the Pipeline**\n",
    "input_text = \"\"\"\n",
    "Acetaminophen is used to treat mild to moderate pain and fever. It is associated with liver damage if taken in high doses.\n",
    "Patients with hepatitis should avoid its usage.\n",
    "\"\"\"\n",
    "#Patient Medical Records:\n",
    "input_text_2 = \"\"\"The patient, a 45-year-old male, presented with complaints of persistent chest pain radiating to the left arm, exacerbated by physical activity, and relieved by rest. \n",
    "Past medical history includes hypertension and type 2 diabetes. No history of smoking or alcohol consumption was noted.\"\"\"\n",
    "\n",
    "#Pathology Reports:\n",
    "input_text_3 = \"\"\"Biopsy of the left breast mass reveals infiltrating ductal carcinoma, Grade II, with positive hormone receptor status. \n",
    "Margins are free of malignancy.\"\"\"\n",
    "\n",
    "#Pharmacovigilance Records:\n",
    "input_text_4 = \"\"\"A 30-year-old female reported severe dizziness and rash following the administration of drug X. \n",
    "Symptoms appeared within 1 hour of ingestion and resolved after discontinuation of the drug.\"\"\"\n",
    "\n",
    "integrated_pipeline(input_text) #input_text, input_text_2, input_text_3, input_text_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a6d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
